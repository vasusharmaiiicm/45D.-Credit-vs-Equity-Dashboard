{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e670e7-6fdc-4f86-888b-69ffbe02ca11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pytz\n",
    "import time\n",
    "import os\n",
    "from xbbg import blp\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact, Dropdown, HBox, VBox, Button, Output, Text, widgets\n",
    "import sympy as sp\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output, update_display\n",
    "from IPython import get_ipython\n",
    "# import backtrader.plot as btplot\n",
    "import matplotlib.dates as mdates\n",
    "from pydataquery import DataQuery\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import warnings\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import yfinance as yf\n",
    "import uuid\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##### Style df\n",
    "def bold_zscore(val):\n",
    "    return 'font-weight: bold' if val else ''\n",
    "\n",
    "def add_black_line(row):\n",
    "    return ['border-bottom: 3px solid black' if row.name in [2, 7, 13, 15, 17, 21] else '' for _ in row]\n",
    "\n",
    "def color_negative_red_positive_green_basis(col: pd.Series):\n",
    "    if col.empty:\n",
    "        return ['' for _ in col]\n",
    "\n",
    "    def safe_float(x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except (ValueError, TypeError):\n",
    "            return None\n",
    "\n",
    "    float_col = col.apply(safe_float)\n",
    "    min_val = float_col.min(skipna=True)\n",
    "    max_val = float_col.max(skipna=True)\n",
    "\n",
    "    def value_to_color(val):\n",
    "        if val is None:\n",
    "            return ''\n",
    "        if val < 0 and min_val < 0:\n",
    "            frac = val / min_val\n",
    "            frac = max(min(frac, 1), 0)\n",
    "            r = int(255 - (255 - 87) * frac)\n",
    "            g = int(255 - (255 - 187) * frac)\n",
    "            b = int(255 - (255 - 138) * frac)\n",
    "            return f'background-color: rgba({r},{g},{b},0.75)'\n",
    "        elif val > 0 and max_val > 0:\n",
    "            frac = val / max_val\n",
    "            frac = max(min(frac, 1), 0)\n",
    "            r = int(255 - (255 - 230) * frac)\n",
    "            g = int(255 - (255 - 135) * frac)\n",
    "            b = int(255 - (255 - 115) * frac)\n",
    "            return f'background-color: rgba({r},{g},{b},0.75)'\n",
    "        return ''\n",
    "\n",
    "    return [value_to_color(v) for v in float_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fccbf4-98ba-424f-90ae-ca08b44f4161",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #ER Code\n",
    "# ####################################################\n",
    "\n",
    "# all_start_date = str((datetime.now()-timedelta(days=6*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#         \"LQD Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_USDLIG_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"HYG Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_USDHY_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"IEAC Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_EURIG_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"IHYG Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_EURHY_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"Fed Fund\": \"FF\",\n",
    "#         \"ER CDX IG 5Y\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX IG 10Y\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX HY 5Y\": \"DB(CDS,TRAC-X,NAHY100UNF05ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX HY 10Y\": \"DB(CDS,TRAC-X,NAHY100UNF10ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX EM 5Y\": \"DB(NEO-UK,credit/cds/index/cdxEM-onrun/5y/JPM_RETURN)\",\n",
    "#         \"ER ITRX MAIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX MAIN 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX XOVER 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX SNRFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX SUBFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# dq = df.copy()\n",
    "\n",
    "# # dq['Fed Fund'] = dq['Fed Fund'].ffill()\n",
    "\n",
    "# end_date = dq.index[-1]\n",
    "# ####################################### BBG Data Acquisition\n",
    "\n",
    "# securities = ['HYG US Equity','EMB US Equity','LQD US Equity','VCIT US Equity',\n",
    "#               'IEAC LN Equity','IHYG LN EQUITY', 'BKLN US EQUITY', 'IBCN GR EQUITY',\n",
    "#               'IEI US Equity','IEF US Equity']\n",
    "\n",
    "# fields1 = ['YAS_MOD_DUR']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields1)\n",
    "# df.columns = [item.split(' ')[0] + ' DUR' for item in securities]\n",
    "# df1 = df.copy()\n",
    "\n",
    "# #################################### Fixing Bad Data Point in YAS of IEI\n",
    "# rolling_avg = df1['IEI DUR'].replace(0, np.nan).rolling(window=30, min_periods=1).mean()\n",
    "# df1['IEI DUR'] = df1.apply(\n",
    "#     lambda row: rolling_avg[row.name] if row['IEI DUR'] == 0.0 else row['IEI DUR'], axis=1\n",
    "# )\n",
    "# #################################### Fixing Bad Data Point in YAS of IEI\n",
    "\n",
    "# securities = ['LT03TRUU INDEX','LT09TRUU INDEX','QW3I INDEX', 'LT03MD INDEX','LT09MD INDEX']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields)\n",
    "# df.columns = ['TR ' + item.split(' ')[0] for item in securities[:3]] + [item.split(' ')[0] + ' DUR' for item in securities[:2]]\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['HYG US Equity','EMB US Equity','LQD US Equity','VCIT US Equity',\n",
    "#               'IEI US Equity','IEF US Equity', 'RSP US EQUITY', #'SPX INDEX',  'RTY INDEX',\n",
    "#               'IBCN GR EQUITY',\n",
    "#               'IEAC LN Equity','IHYG LN EQUITY', 'BKLN US EQUITY',\n",
    "#               'GSCBHYEQ Index', 'GSCBIGEQ Index', 'SPY US EQUITY', 'EEM US EQUITY', 'IWM US EQUITY', 'IJH US EQUITY',\n",
    "#              ]\n",
    "\n",
    "# fields = ['TOT_RETURN_INDEX_GROSS_DVDS']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields)\n",
    "# df.columns = ['TR ' + item.split(' ')[0] for item in securities] \n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['QW3I INDEX']\n",
    "# fields = ['MODIFIED_DURATION']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields)\n",
    "# df.columns = [item.split(' ')[0] + ' DUR' for item in securities]\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# # securities = ['SPXFP INDEX', 'RTYFPE INDEX','SX5EFSER Index']  ############## I want to calculate funding rate for spx, rty and sx5e separately\n",
    "# # fields = ['PX_LAST']\n",
    "# # df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields)\n",
    "# # df.columns = ['ER SPX','ER RTY','ER SX5E']\n",
    "# # df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['EURR002W Index']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields)\n",
    "# df.columns = ['ECB Rate']\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# bbg = df1.copy()\n",
    "# dq.index = pd.to_datetime(dq.index)\n",
    "# dq.index = dq.index.date\n",
    "# bbg.index = pd.to_datetime(bbg.index)\n",
    "# bbg.index = bbg.index.date\n",
    "\n",
    "# data = pd.concat([dq,bbg],axis=1)\n",
    "# data = data.sort_index()\n",
    "\n",
    "# df_funding = data[[col for col in data.columns if ('Funding Sprd' in col)]+['Fed Fund']+['ECB Rate']]\n",
    "\n",
    "# if np.isnan(df_funding.loc[df_funding.index[-1],'Fed Fund']):\n",
    "#     df_funding.loc[df_funding.index[-1],'Fed Fund'] = df_funding.loc[df_funding.index[-2],'Fed Fund']\n",
    "\n",
    "# # df_funding['Fed Fund'] = df_funding['Fed Fund'].ffill()\n",
    "\n",
    "# for col in df_funding:\n",
    "#     if col.endswith('Sprd'):\n",
    "#         if col.split(' ')[0] in ['HYG','LQD']:\n",
    "#             df_funding[f'Net Long {col.replace(\" Sprd\",\"\")}'] = (df_funding['Fed Fund'] + df_funding[f'{col}']/100) + 0.25/100\n",
    "#             df_funding[f'Net Short {col.replace(\" Sprd\",\"\")}'] = (df_funding['Fed Fund'] + df_funding[f'{col}']/100) - 0.25/100\n",
    "#         if col.split(' ')[0] in ['IHYG','IEAC']:\n",
    "#             df_funding[f'Net Long {col.replace(\" Sprd\",\"\")}'] = (df_funding['ECB Rate'] + df_funding[f'{col}']/100) + 0.25/100\n",
    "#             df_funding[f'Net Short {col.replace(\" Sprd\",\"\")}'] = (df_funding['ECB Rate'] + df_funding[f'{col}']/100) - 0.25/100\n",
    "\n",
    "# df_funding['Net Long VCIT Funding'] = df_funding['Net Long LQD Funding']\n",
    "# df_funding['Net Short VCIT Funding'] = df_funding['Net Short LQD Funding']\n",
    "\n",
    "# for item in ['EMB','EEM']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['Fed Fund'] + 0.5\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['Fed Fund'] - 0.5\n",
    "\n",
    "# for item in ['IEI', 'IEF', 'RSP', 'BKLN', 'GSCBHYEQ', 'GSCBIGEQ', 'SPX', 'RTY', 'SPY', 'IWM', 'IJH']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['Fed Fund'] + 0.15\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['Fed Fund'] - 0.15\n",
    "\n",
    "# for item in ['IBCN','SX5E']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['ECB Rate'] + 0.15\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['ECB Rate'] - 0.15\n",
    "\n",
    "# df_funding = df_funding[[col for col in df_funding.columns if col.startswith(\"Net\")]]\n",
    "# df_funding.index = pd.to_datetime(df_funding.index)\n",
    "# df_funding = df_funding.resample('D').last().ffill()\n",
    "\n",
    "# original_er_data = data[[col for col in data.columns if col.startswith(\"ER \")]]\n",
    "# tr_data = data[[col for col in data.columns if col.startswith(\"TR \")]]\n",
    "# ust = tr_data[['TR LT09TRUU']] # for using corr later\n",
    "# tr_data = tr_data.iloc[:,:-3] #dropping LT03/09 and QW3I\n",
    "\n",
    "# tr_data.index = pd.to_datetime(tr_data.index).date\n",
    "# df_funding.index = pd.to_datetime(df_funding.index).date\n",
    "\n",
    "# er_tr_data = pd.concat([tr_data,df_funding],axis=1)\n",
    "# er_tr_data = er_tr_data.sort_index()\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# etfs = [col for col in er_tr_data.columns if col.startswith(\"TR \")]\n",
    "\n",
    "# for item in etfs:\n",
    "#     check = er_tr_data[item].dropna()\n",
    "#     check = check.diff()/check.shift()\n",
    "#     check = check.reindex(er_tr_data.index)\n",
    "#     er_tr_data[item] = check\n",
    "    \n",
    "# er_tr_data['Date'] = pd.to_datetime(er_tr_data.index)\n",
    "# er_tr_data['Days'] = (er_tr_data['Date'] - er_tr_data['Date'].shift()).dt.days\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# ############################################################### Funding Sprds\n",
    "# funding = er_tr_data[[col for col in er_tr_data.columns if 'Funding' in col]].copy()\n",
    "# x = er_tr_data[[col for col in er_tr_data.columns if 'Funding' in col]].copy()\n",
    "# x = x.interpolate()\n",
    "# x.to_excel(\"Funding Rates.xlsx\")\n",
    "\n",
    "# y = x.copy()\n",
    "# y = round(y,2)\n",
    "# y.to_excel(\"Funding Rates 2.xlsx\")\n",
    "\n",
    "# ###############################################################\n",
    "# for item in etfs:\n",
    "#     name = item.split(' ')[1]\n",
    "#     er_tr_data[f'ER {name}'] = er_tr_data[item] - \\\n",
    "#                 (1/100)*(er_tr_data['Days']/360)*(0.5*(er_tr_data[f'Net Long {name} Funding'] + er_tr_data[f'Net Short {name} Funding']))\n",
    "\n",
    "\n",
    "# er_tr_data = er_tr_data[[col for col in er_tr_data.columns if col.startswith(\"ER \")]]\n",
    "# er_tr_data = (1+er_tr_data).cumprod()\n",
    "\n",
    "# tr_data.index = pd.to_datetime(tr_data.index).date\n",
    "# df_funding.index = pd.to_datetime(df_funding.index).date\n",
    "\n",
    "# er_tr_data = pd.concat([tr_data,df_funding],axis=1)\n",
    "# er_tr_data = er_tr_data.sort_index()\n",
    "\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# etfs = [col for col in er_tr_data.columns if col.startswith(\"TR \")]\n",
    "\n",
    "# for item in etfs:\n",
    "#     check = er_tr_data[item].dropna()\n",
    "#     check = check.diff()/check.shift()\n",
    "#     check = check.reindex(er_tr_data.index)\n",
    "#     er_tr_data[item] = check\n",
    "\n",
    "# er_tr_data['Date'] = pd.to_datetime(er_tr_data.index)\n",
    "# er_tr_data['Days'] = (er_tr_data['Date'] - er_tr_data['Date'].shift()).dt.days\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# for item in etfs:\n",
    "#     name = item.split(' ')[1]\n",
    "#     er_tr_data[f'ER {name}'] = er_tr_data[item] - \\\n",
    "#                 (1/100)*(er_tr_data['Days']/360)*(0.5*(er_tr_data[f'Net Long {name} Funding'] + er_tr_data[f'Net Short {name} Funding']))\n",
    "\n",
    "# er_tr_data = er_tr_data[[col for col in er_tr_data.columns if col.startswith(\"ER \")]]\n",
    "# er_tr_data = (1+er_tr_data).cumprod()\n",
    "\n",
    "# er_data = pd.concat([original_er_data,er_tr_data],axis=1)\n",
    "# # er_data = er_data.dropna()\n",
    "# # er_data.columns = er_data.columns.str.replace(\"ER SPX\",\"ER ESA\").str.replace(\"ER RTY\",\"ER RTYA\").str.replace(\"ER SX5E\",\"ER VGA\")\n",
    "# er_data.columns = er_data.columns.str.replace(\"ER GSCBHYEQ\",\"ER HY Eqty\").str.replace(\"ER GSCBIGEQ\",\"ER IG Eqty\")\n",
    "# er_data = er_data.sort_index()\n",
    "\n",
    "# securities = ['SPXFP INDEX', 'RTYFPE INDEX','SX5EFSER Index']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = er_data.index[0], flds = fields)\n",
    "# df.columns = ['ER SPX','ER RTY','ER SX5E']\n",
    "# er_data = pd.concat([er_data,df], axis=1)\n",
    "# er_data = er_data.sort_index()\n",
    "\n",
    "# er_data.to_csv(\"All ER.csv\")\n",
    "\n",
    "# ##############################################################  Updating Durations\n",
    "\n",
    "# all_start_date = str((datetime.now()-timedelta(days=6*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#         \"CDX IG 5Y Dur\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_DUR)\",\n",
    "#         \"CDX IG 10Y Dur\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_DUR)\",\n",
    "#         \"ITRX XOVER 5Y Dur\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_DUR)\",\n",
    "#         \"ITRX MAIN 5Y Dur\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_DUR)\",\n",
    "#         \"ITRX MAIN 10Y Dur\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_DUR)\",\n",
    "#         \"ITRX SUBFIN 5Y Dur\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_DUR)\",\n",
    "#         \"ITRX SNRFIN 5Y Dur\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_DUR)\",\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# df.index = pd.to_datetime(df.index)\n",
    "# df.loc[pd.to_datetime(datetime.now().date())] = [item - ((datetime.now() - df.index[-1]).days)/365 for item in list(df.iloc[-1])]\n",
    "# df = df.interpolate()\n",
    "# all_dq_dur = df.copy()\n",
    "# all_dq_dur.to_excel(\"All DQ Duration.xlsx\")\n",
    "\n",
    "# ############################################################################## Updating Ref levels\n",
    "\n",
    "# all_start_date = str((datetime.now()-timedelta(days=6*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#     \"CDX IG 5Y\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX IG 10Y\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX HY 5Y\": \"DB(CDS,TRAC-X,NAHY100UNF05ONRUN,JPM_CLEAN_MID)\",\n",
    "#     \"ITRX MAIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX MAIN 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX SNRFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX SUBFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX XOVER 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX EM 5Y\": \"DB(NEO-UK,credit/cds/index/cdxEM-onrun/5y/JPM_CLEAN_MID)\",\n",
    "\n",
    "#     \"CDX IG 5Y DUR\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_DUR)\",\n",
    "#     \"CDX IG 10Y DUR\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_DUR)\",\n",
    "#     \"ITRX MAIN 5Y DUR\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX MAIN 10Y DUR\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_DUR)\",\n",
    "#     \"ITRX SNRFIN 5Y DUR\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX SUBFIN 5Y DUR\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX XOVER 5Y DUR\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_DUR)\",\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "# df.index = pd.to_datetime(df.index)\n",
    "# df.to_excel(\"Ref Levels.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e454257-447a-4edb-9780-c2be8d0388a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "roll_series = {\n",
    "    \"CDX IG 5Y\": {\n",
    "        \"S44\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S45\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S46\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S47\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "    },\n",
    "    \"CDX HY 5Y\": {\n",
    "        \"S44\": [\"2025-07-04\", \"2026-01-04\"],\n",
    "        \"S45\": [\"2026-01-05\", \"2026-07-03\"],\n",
    "        \"S46\": [\"2026-07-04\", \"2027-01-03\"],\n",
    "        \"S47\": [\"2027-01-04\", \"2027-07-05\"]\n",
    "    },\n",
    "    \"CDX EM 5Y\": {\n",
    "        \"S43\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S44\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S45\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S46\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "    },\n",
    "    \"ITRX MAIN 5Y\": {\n",
    "        \"S43\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S44\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S45\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S46\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "    },\n",
    "    \"ITRX XOVER 5Y\": {\n",
    "        \"S43\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S44\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S45\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S46\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "    },\n",
    "    \"ITRX SNRFIN 5Y\": {\n",
    "        \"S43\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S44\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S45\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S46\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "    },\n",
    "    \"ITRX SUBFIN 5Y\": {\n",
    "        \"S43\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S44\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S45\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S46\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4a8e4bb-f946-47e8-93f3-a1d0935fd309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CDX IG 5Y': 'S44',\n",
       " 'CDX HY 5Y': 'S44',\n",
       " 'CDX EM 5Y': 'S43',\n",
       " 'ITRX MAIN 5Y': 'S43',\n",
       " 'ITRX XOVER 5Y': 'S43',\n",
       " 'ITRX SNRFIN 5Y': 'S43',\n",
       " 'ITRX SUBFIN 5Y': 'S43'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.now()\n",
    "current_series = {}\n",
    "for key, val in roll_series.items():\n",
    "    for series, dates_list in val.items():\n",
    "        if pd.to_datetime(dates_list[0])<= today and today<=pd.to_datetime(dates_list[1]):\n",
    "            current_series[key] = series\n",
    "current_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53296c-7cfc-4705-bd3c-dd2e3ae925b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a7399-5bbe-4b25-be96-5a9ce99e3b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183178b9-ee51-434f-bc3e-e98c32557cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b9e5a-7952-43eb-ac7a-8d97d3a917bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b0c5ad-9596-4892-8828-c7a78fc078e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dq_dur = pd.read_excel(\"All DQ Duration.xlsx\")\n",
    "all_dq_dur['Date'] = pd.to_datetime(all_dq_dur['Date'])\n",
    "all_dq_dur = all_dq_dur.set_index('Date')\n",
    "\n",
    "dict_map = {\n",
    "# product type, start time, end time, carry (%), trades on sprd, slippage (bps or $),\n",
    "# fixed commission, notional (if selected as Y), BBG ticker, check live status using which ticker\n",
    "    'CDX IG 5Y': ['CDX', '07:30:00', '20:00:00', 1, 'Yes', 0.15, 500, 30*10**6, \"CDX IG CDSI GEN 5Y CORP\", \"CDX IG CDSI GEN 5Y CORP\"],\n",
    "    'CDX IG 10Y': ['CDX', '07:30:00', '20:00:00', 1, 'Yes', 0.3, 500, 30*10**6, \"CDX IG CDSI GEN 10Y CORP\", \"CDX IG CDSI GEN 5Y CORP\"],\n",
    "    'CDX HY 5Y': ['CDX', '07:30:00', '20:00:00', 5, 'No', 0.02, 500, 6*10**6, \"CDX HY CDSI GEN 5Y CORP\", \"CDX IG CDSI GEN 5Y CORP\"],\n",
    "    'SPX': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"SPX INDEX\", \"ESA INDEX\"],\n",
    "    'SPY': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"SPY US EQUITY\", \"ESA INDEX\"],\n",
    "    'IWM': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"IWM US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'RSP': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"RSP US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'RTY': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"RTY INDEX\", \"RSP US EQUITY\"],\n",
    "    'IG Eqty': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"GSCBIGEQ Index\", \"RSP US EQUITY\"],\n",
    "    'HY Eqty': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"GSCBHYEQ Index\", \"RSP US EQUITY\"],\n",
    "    'ITRX MAIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 500, 30*10**6, \"ITRX EUR CDSI GEN 5Y CORP\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX MAIN 10Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.3, 500, 30*10**6, \"ITRX EUR CDSI GEN 10Y CORP\", \"ITRX EUR CDSI GEN 10Y CORP\"],\n",
    "    'ITRX SNRFIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 500, 30*10**6, \"SNRFIN CDSI GEN 5Y Corp\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX SUBFIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 500, 30*10**6, \"SUBFIN CDSI GEN 5Y Corp\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX XOVER 5Y': ['CDX', '03:30:00', '11:59:00', 5, 'Yes', 0.15, 500, 6*10**6, \"ITRX XOVER CDSI GEN 5Y CORP\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX XOVER 10Y': ['CDX', '03:30:00', '11:59:00', 5, 'Yes', 0.3, 500, 6*10**6, \"ITRX XOVER CDSI GEN 10Y CORP\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    # 'VIX': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"VIX INDEX\", \"RSP US EQUITY\"],\n",
    "    # 'V2X': ['Eq', '03:30:00', '11:59:00', 0, 'No', 0.01, 0, 10**6, \"V2X INDEX\", \"SX5E INDEX\"],\n",
    "    'SX5E': ['Eq', '03:30:00', '11:59:00', 0, 'No', 0.01, 0, 10**6, \"SX5E INDEX\", \"SX5E INDEX\"],\n",
    "    'CDX EM 5Y': ['CDX', '07:30:00', '20:00:00', 1, 'No', 0.02, 500, 6*10**6, \"CDX EM CDSI GEN 5Y CORP\", \"CDX IG CDSI GEN 5Y CORP\"],\n",
    "    'HYG': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"HYG US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'EMB': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"EMB US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'VCIT': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"VCIT US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'LQD': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"LQD US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'IEI': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"IEI US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'IEF': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"IEF US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'EEM': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"EEM US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'IJH': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"IJH US EQUITY\", \"RSP US EQUITY\"],\n",
    "}\n",
    "\n",
    "l1 = list(dict_map.keys())\n",
    "l2 = [item[8] for item in list(dict_map.values())]\n",
    "reverse_dict = dict(zip(l2,l1))\n",
    "reverse_dict[\"ESA INDEX\"] = \"ESA\"\n",
    "\n",
    "live_dict = dict(zip([item[8] for item in dict_map.values()], [item[9] for item in dict_map.values()]))\n",
    "live_dict[\"ESA INDEX\"] = \"ESA INDEX\"\n",
    "\n",
    "last_checked = None\n",
    "current_date_esa_close = datetime.now()\n",
    "first_current_date_esa_close = True\n",
    "first_run = True\n",
    "\n",
    "df = pd.read_excel(\"Data for Credit-Eqty Dashboard v3.xlsx\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date')\n",
    "df = df.sort_index()\n",
    "bbg_datafile = df.copy()\n",
    "last_update = df.dropna().index[-1]\n",
    "all_bbg_tickers = [dict_map[item][8] for item in df.columns]\n",
    "new_data = pd.DataFrame()\n",
    "\n",
    "for bbg_tickers in all_bbg_tickers:\n",
    "    bbg_date = pd.to_datetime(last_update.date())\n",
    "    data = None\n",
    "    while True:\n",
    "        try:\n",
    "            f = blp.bdib(ticker = bbg_tickers, dt = bbg_date, interval = 1, ref='IndexYieldCurve')      \n",
    "        except:\n",
    "            if bbg_date > pd.to_datetime(datetime.now().date()):\n",
    "                break\n",
    "        data = pd.concat([data,f])\n",
    "        bbg_date += timedelta(days=1)    \n",
    "    try:\n",
    "        data = data.iloc[:,[3]].copy()\n",
    "        data.columns = [bbg_tickers]\n",
    "    except:\n",
    "        continue\n",
    "    new_data = pd.concat([new_data, data],axis=1)\n",
    "\n",
    "new_data.index = new_data.index.tz_convert('America/New_York')\n",
    "new_data.index = new_data.index.tz_localize(None)\n",
    "\n",
    "live_list = ['CDX IG CDSI GEN 5Y CORP','ITRX EUR CDSI GEN 5Y CORP', 'RSP US EQUITY','SX5E INDEX','ESA INDEX']\n",
    "mask = blp.bdh(tickers = live_list, flds='PX_LAST', start_date = df.index[0]-timedelta(days=5))\n",
    "mask.columns = live_list\n",
    "mask.index = pd.to_datetime(mask.index).date\n",
    "\n",
    "new_data = new_data.ffill()\n",
    "new_data.index = pd.to_datetime(new_data.index)\n",
    "new_data.columns = [reverse_dict[item] for item in new_data.columns]\n",
    "\n",
    "bbg_datafile = bbg_datafile[bbg_datafile.index<new_data.index[0]].copy()\n",
    "bbg_datafile = pd.concat([bbg_datafile, new_data])\n",
    "bbg_datafile = bbg_datafile.sort_index()\n",
    "bbg_datafile.index.name = 'Date'\n",
    "bbg_datafile = bbg_datafile.ffill().copy()\n",
    "bbg_datafile = bbg_datafile[~bbg_datafile.index.duplicated(keep='last')]\n",
    "\n",
    "bbg_datafile['Date'] = pd.to_datetime(bbg_datafile.index.date)\n",
    "bbg_datafile['Time'] = bbg_datafile.index.time\n",
    "filtered_new_data = None\n",
    "\n",
    "for col in bbg_datafile.drop(['Date','Time'],axis=1).columns:\n",
    "    test = bbg_datafile[[col,'Date','Time']]\n",
    "    cond = (test['Date'].isin(mask[dict_map[col][9]].dropna().index)) & (test['Time']<=pd.\\\n",
    "            to_datetime(dict_map[col][2]).time()) & (test['Time']>=pd.to_datetime(dict_map[col][1]).time())\n",
    "    test = test[cond][[col]]\n",
    "    filtered_new_data = pd.concat([filtered_new_data, test],axis=1)\n",
    "\n",
    "bbg_datafile = filtered_new_data.copy()\n",
    "\n",
    "bbg_datafile = bbg_datafile.dropna(how='all')\n",
    "bbg_datafile.to_excel(\"Data for Credit-Eqty Dashboard v3.xlsx\")    \n",
    "master_bbg_datafile = bbg_datafile.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52886c5-8fc6-4571-be61-942a429d6a1c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Ref Levels.xlsx\", index_col=0, parse_dates=True)\n",
    "\n",
    "ref = df[[col for col in df.columns if not col.endswith(\"DUR\")]]\n",
    "\n",
    "dur = df[[col for col in df.columns if col.endswith(\"DUR\")]]\n",
    "dur.loc[datetime.now()] = [np.nan] * len(dur.columns)\n",
    "dur = dur.resample(\"D\").last().ffill().copy()\n",
    "dur = dur.shift().resample(\"1min\").last().ffill().copy()  ############ yesterday's duration we take .. we have shifted it here\n",
    "dur.columns = [item.rsplit(\" \",1)[0] + '_dq_dur' for item in dur.columns]\n",
    "\n",
    "#########################################################################################\n",
    "bbg_tickers = [dict_map[item][8] for item in dict_map.keys()]\n",
    "# reverse_dict = dict(zip(bbg_tickers, list(dict_map.keys())))\n",
    "bbg_data = blp.bdh(tickers = bbg_tickers, flds='px_last', start_date='2017-01-01')\n",
    "bbg_data.columns = bbg_tickers\n",
    "bbg_data.index = pd.to_datetime(bbg_data.index)\n",
    "bbg_data.columns = [reverse_dict[item] for item in bbg_data.columns]\n",
    "\n",
    "for col in ref.columns:\n",
    "    bbg_data[col] = ref[col]\n",
    "\n",
    "bbg_data['ESA'] = bbg_data['SPY']\n",
    "\n",
    "bbg_data1 = bbg_data.resample(\"1min\").last().ffill().copy()\n",
    "bbg_data1.columns = [item +'_bbg_px' for item in bbg_data1.columns]\n",
    "\n",
    "bbg_data2 = bbg_data.shift().resample(\"1min\").last().ffill().copy()\n",
    "bbg_data2.columns = [item +'_bbg_px_2' for item in bbg_data2.columns]\n",
    "\n",
    "################################################## Creating SPY Imputed for recent day in BBG_DATFILE\n",
    "\n",
    "bbg_datafile[\"ESA\"] = bbg_datafile[\"SPY\"]\n",
    "\n",
    "last_close = None\n",
    "for tick in ['ESA INDEX','SPY US EQUITY']:\n",
    "    f = blp.bdib(ticker=tick, flds='PX_LAST', dt=str(list(sorted(set(bbg_datafile[['SPY']].dropna().index.date)))[-2]), ref='IndexUS')\n",
    "    f.index = f.index.tz_convert('America/New_York').tz_localize(None)\n",
    "    f = f.iloc[:,[3]]\n",
    "    f.columns = [tick]\n",
    "    last_close = pd.concat([last_close,f],axis=1)\n",
    "\n",
    "esa_val = last_close['ESA INDEX'].ffill().iloc[-1]\n",
    "spx_val = last_close['SPY US EQUITY'].iloc[-1]\n",
    "\n",
    "tick = \"ESA INDEX\"\n",
    "start_date = list(sorted(set(bbg_datafile[['SPY']].dropna().index.date)))[-1]\n",
    "all_f = None\n",
    "for i in range(4):\n",
    "    try:\n",
    "        f = blp.bdib(ticker=tick, flds='PX_LAST', dt=str(start_date+timedelta(days=i)), ref='IndexYieldCurve')\n",
    "        f.index = f.index.tz_convert('America/New_York').tz_localize(None)\n",
    "        f = f.iloc[:,[3]]\n",
    "        f.columns = [tick]\n",
    "        all_f = pd.concat([f, all_f]).sort_index().copy()\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "f = all_f.copy()\n",
    "f = f[f.index.date == pd.to_datetime(str(list(sorted(set(bbg_datafile[['SPY']].dropna().index.date)))[-1])).date()]\n",
    "f['SPY Imputed'] = round((f/esa_val) * spx_val,2)\n",
    "f = f[['SPY Imputed']].copy()\n",
    "f.columns = ['ESA']\n",
    "\n",
    "recent_spy = bbg_datafile[bbg_datafile.index.date<list(sorted(set(bbg_datafile[['SPY']].dropna().index.date)))[-1]][['ESA']]\n",
    "new_spy = pd.concat([recent_spy, f]).sort_index().copy()\n",
    "bbg_datafile = pd.concat([bbg_datafile.drop(\"ESA\",axis=1), new_spy], axis=1).sort_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "691bfc3a-471a-40f5-ae22-e9c4210f28d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = bbg_datafile.copy()\n",
    "er_data = pd.read_csv(\"All ER.csv\",index_col=0, parse_dates=True)\n",
    "\n",
    "er_data.loc[datetime.now().date()] = [np.nan] * len(er_data.columns)\n",
    "er_data.index = pd.to_datetime(er_data.index)\n",
    "er_data = er_data.resample(\"D\").last().ffill().copy()\n",
    "er_data.columns = [item.split(\"ER \",1)[1] for item in er_data.columns]\n",
    "er_data[['ESA']] = er_data[['SPY']]\n",
    "\n",
    "er = er_data.copy()\n",
    "er.columns = [item + '_dq_ER' for item in er.columns]\n",
    "er = er.resample(\"1min\").last().ffill().copy()\n",
    "\n",
    "er2 = er_data.shift().copy()\n",
    "er2.columns = [item + '_dq_ER_2' for item in er2.columns]\n",
    "er2 = er2.resample(\"1min\").last().ffill().copy()\n",
    "\n",
    "############################################################ Converting historical price series into historical er series\n",
    "\n",
    "intraday_tr_data = None\n",
    "\n",
    "for col in df.columns:    \n",
    "    first_run = False\n",
    "    if col == \"ESA\":\n",
    "        first_run = True\n",
    "    elif dict_map[col][0] == \"Eq\" or (dict_map[col][0] == \"CDX\" and dict_map[col][4] == 'No'):\n",
    "        first_run = True\n",
    "    \n",
    "    if first_run:\n",
    "        x = pd.concat([df[[col]], er[[f'{col}_dq_ER']], er2[[f'{col}_dq_ER_2']], bbg_data1[[f'{col}_bbg_px']],\\\n",
    "           bbg_data2[[f'{col}_bbg_px_2']],], axis=1).sort_index().dropna().copy()\n",
    "        \n",
    "        x['TR Change'] = (x[f'{col}_dq_ER'] / x[f'{col}_dq_ER_2'] - 1)\n",
    "        \n",
    "        if col in [\"CDX HY 5Y\", \"CDX HY 10Y\", \"CDX EM 5Y\"]:\n",
    "            x['d-o-d px pnl'] = (x[f'{col}_bbg_px'] - x[f'{col}_bbg_px_2']) * 10**(-2)\n",
    "            x['intraday px pnl'] = (x[col] - x[f'{col}_bbg_px_2']) * 10**(-2)\n",
    "        else:\n",
    "            x['d-o-d px pnl'] = (x[f'{col}_bbg_px']/ x[f'{col}_bbg_px_2'] - 1)\n",
    "            x['intraday px pnl'] = (x[col] / x[f'{col}_bbg_px_2'] - 1)\n",
    "            \n",
    "        x['Calculated TR Change'] = x['TR Change'] - x['d-o-d px pnl'] + x['intraday px pnl']\n",
    "        # x['Actual TR Series'] = (1 + x['Calculated TR Change']) * x[f'{col}_dq_ER_2']\n",
    "        # x = x[['Actual TR Series']].copy()\n",
    "        # x.columns = [col]\n",
    "    \n",
    "    \n",
    "    elif dict_map[col][4] == 'Yes':\n",
    "        x = pd.concat([df[[col]], er[[f'{col}_dq_ER']], er2[[f'{col}_dq_ER_2']], bbg_data1[[f'{col}_bbg_px']], bbg_data2[[f'{col}_bbg_px_2']],\n",
    "            dur[[f'{col}_dq_dur']]], axis=1).sort_index()#.dropna().copy()\n",
    "        x['TR Change'] = (x[f'{col}_dq_ER'] / x[f'{col}_dq_ER_2'] - 1)\n",
    "        x['d-o-d sprd pnl'] = (-1) * (x[f'{col}_dq_dur']) * (x[f'{col}_bbg_px'] - x[f'{col}_bbg_px_2']) * 10**(-4)\n",
    "        x['intraday sprd pnl'] = (-1) * (x[f'{col}_dq_dur']) * (x[col] - x[f'{col}_bbg_px_2']) * 10**(-4)\n",
    "        \n",
    "        x['Calculated TR Change'] = x['TR Change'] - x['d-o-d sprd pnl'] + x['intraday sprd pnl']\n",
    "    x['Actual TR Series'] = (1 + x['Calculated TR Change']) * x[f'{col}_dq_ER_2']\n",
    "    x = x[['Actual TR Series']].copy()\n",
    "    x.columns = [col]   \n",
    "    intraday_tr_data = pd.concat([intraday_tr_data, x], axis=1)\n",
    "\n",
    "######################################################################################### Getting ref levels from last close\n",
    "\n",
    "intraday_tr_data1 = intraday_tr_data[intraday_tr_data.index.date<datetime.now().date()].dropna(how='all').copy()\n",
    "last_dict = {}\n",
    "for col in intraday_tr_data1.columns:\n",
    "    last_ref = bbg_datafile.loc[intraday_tr_data1[[col]].dropna().index[-1]][col]\n",
    "    last_date = str(intraday_tr_data1[[col]].dropna().index[-1].date())\n",
    "    last_dict[col] = [intraday_tr_data1[col].dropna().iloc[-1], last_ref, last_date]\n",
    "\n",
    "\n",
    "######################################################################################### calculating today's er series\n",
    "funding = pd.read_excel(\"Funding Rates.xlsx\",index_col=0, parse_dates=True)\n",
    "funding.columns = funding.columns.str.replace(\"GSCBHYEQ\",\"HY Eqty\").str.replace(\"GSCBIGEQ\",\"IG Eqty\")\n",
    "funding['Net Long ESA Funding'] = funding['Net Long SPY Funding']\n",
    "funding['Net Short ESA Funding'] = funding['Net Short SPY Funding']\n",
    "\n",
    "recent_bbg_datafile = bbg_datafile[bbg_datafile.index.date == datetime.now().date()].copy()\n",
    "all_today_er_series = None\n",
    "\n",
    "for col in recent_bbg_datafile.columns:\n",
    "    carry_days = (datetime.now() - pd.to_datetime(last_dict[col][2])).days\n",
    "    x = recent_bbg_datafile[[col]].dropna().copy()\n",
    "    \n",
    "    first_run = False\n",
    "    if col==\"ESA\":\n",
    "        first_run = True\n",
    "    elif dict_map[col][0] == \"Eq\":\n",
    "        first_run = True\n",
    "        \n",
    "    if first_run:\n",
    "        rate = funding[[item for item in funding.columns if col == item.split(\" \",2)[2].rsplit(\" \",1)[0]]].dropna().iloc[-1]\n",
    "        rate = rate.mean()   ############ etf funding rate\n",
    "        x = (last_dict[col][0])*((x/last_dict[col][1])-(rate/100)*(carry_days/360))\n",
    "    elif dict_map[col][4] == \"Yes\":\n",
    "        x = (last_dict[col][0])*(1 - dur[f'{col}_dq_dur'].iloc[-1]*(x-last_dict[col][1])*(10**(-4))+(dict_map[col][3]/100)*(carry_days/360))\n",
    "    elif dict_map[col][0] == \"CDX\":\n",
    "        x = (last_dict[col][0])*(1 + (x-last_dict[col][1])*(10**(-2))+(dict_map[col][3]/100)*(carry_days/360))\n",
    "\n",
    "    all_today_er_series = pd.concat([all_today_er_series, x], axis=1)\n",
    "all_intraday_er_series = pd.concat([intraday_tr_data1, all_today_er_series]).sort_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d53d2a3-7e40-4dd2-832b-1cbab3ada7af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dict_models = {\n",
    "    # 1 : [\"Intraday\",252,252,'A (Intraday; 12M)'],\n",
    "    # 2 : [\"Intraday\",315,315,'B (Intraday; 15M)'],\n",
    "    3 : [\"Intraday\",378,378,'C (Intraday; 18M)'],\n",
    "}\n",
    "\n",
    "def x_model(model_num, models_list, diff_var, calc_method):\n",
    "    all_zplots = None\n",
    "    val = []\n",
    "    \n",
    "    for global_model in models_list:    \n",
    "        model_Y = global_model[0]\n",
    "        model_X = global_model[1]\n",
    "        zscore_Y = global_model[2]\n",
    "        zscore_X = global_model[3]\n",
    "    \n",
    "        backtest_start_date = pd.to_datetime('2021-12-01')\n",
    "        \n",
    "        zscore_vars = [model_Y, zscore_Y] + model_X + zscore_X\n",
    "        zscore_vars = list(set(zscore_vars))\n",
    "        \n",
    "        if 'ESA' in zscore_vars:\n",
    "            zscore_vars_start_time = '07:30:00'\n",
    "            zscore_vars_end_time = '20:00:00'\n",
    "    \n",
    "        # elif ('ITRX XOVER 5Y' in zscore_vars) and ('CDX HY 5Y' in zscore_vars):\n",
    "        #     zscore_vars_start_time = '07:15:00'\n",
    "        #     zscore_vars_end_time = min([dict_map[item][2] for item in zscore_vars])\n",
    "    \n",
    "        else:\n",
    "            zscore_vars_start_time = max([dict_map[item][1] for item in zscore_vars])\n",
    "            zscore_vars_end_time = min([dict_map[item][2] for item in zscore_vars])\n",
    "        \n",
    "        ################################## Beta Calculation\n",
    "\n",
    "        # if len(model_X) == 1:\n",
    "        #     er_Y = f'ER {model_Y}'\n",
    "        #     er_X = f'ER {model_X[0]}'\n",
    "        #     er_data = pd.read_csv(\"All ER.csv\")\n",
    "        #     er_data.columns = ['Date'] + list(er_data.columns)[1:]\n",
    "        #     er_data['Date'] = pd.to_datetime(er_data['Date'])\n",
    "        #     er_data = er_data.set_index('Date')\n",
    "        #     er_data = er_data.sort_index()\n",
    "        #     beta = er_data[[er_Y, er_X]].dropna()\n",
    "        #     beta = beta.resample('W').last()\n",
    "        #     beta = np.log(beta)\n",
    "        #     beta = beta.diff().dropna()\n",
    "        #     beta['Beta1'] = [np.nan] * len(beta)\n",
    "        #     beta['Beta2'] = [np.nan] * len(beta)\n",
    "            \n",
    "        #     for i in range(len(beta)-24+1):\n",
    "        #         reg_X = beta[er_X].iloc[i:i+24]\n",
    "        #         reg_Y = beta[er_Y].iloc[i:i+24]\n",
    "        #         model = sm.OLS(reg_Y, sm.add_constant(reg_X)).fit() \n",
    "        #         beta.iloc[i+23,2] = model.params.iloc[1]\n",
    "            \n",
    "        #         model = sm.OLS(reg_X, sm.add_constant(reg_Y)).fit() \n",
    "        #         beta.iloc[i+23,3] = model.params.iloc[1]\n",
    "            \n",
    "        #     beta['Beta1'] = beta['Beta1'].rolling(104).mean()\n",
    "        #     beta['Beta2'] = beta['Beta2'].rolling(104).mean()\n",
    "        #     beta['Beta'] = 0.5*(beta['Beta1'] + 1/ beta['Beta2'])\n",
    "        #     beta = beta[['Beta']].dropna()\n",
    "        # else:\n",
    "        #     ############################################################# Update this beta calculation\n",
    "    \n",
    "        #     b1 = pd.read_csv(\"All Basis Trade Betas.csv\")\n",
    "        #     b1.columns = ['Date'] + list(b1.columns)[1:]\n",
    "        #     b1 = b1.set_index('Date')\n",
    "        #     beta = b1[[f'{model_Y}_{model_X[0]}_{model_X[1]}']]\n",
    "        #     beta.columns = ['Beta']\n",
    "        #     beta['Coef1'] = beta['Beta'].apply(lambda x: eval(x)[0])\n",
    "        #     beta['Coef2'] = beta['Beta'].apply(lambda x: eval(x)[1])\n",
    "        #     beta.index = pd.to_datetime(beta.index)\n",
    "            \n",
    "        # # beta = beta.resample(sampling_freq).first().ffill()\n",
    "        # beta = beta.resample(\"1min\").first().ffill()\n",
    "        \n",
    "        beta = None\n",
    "        \n",
    "        ######################################## Getting data from the master file......\n",
    "        if calc_method == \"Price\":\n",
    "            df = bbg_datafile.copy()    \n",
    "        elif calc_method == \"Return\":\n",
    "            df = all_intraday_er_series.copy()\n",
    "        \n",
    "        zscore_df = df[zscore_vars].between_time(zscore_vars_start_time, zscore_vars_end_time).copy()\n",
    "        zscore_df3 = zscore_df.copy()\n",
    "        valid_dates = zscore_df3.index.date\n",
    "        zscore_df3 = zscore_df3.iloc[-6000:].resample(\"1min\").last().ffill().copy()\n",
    "        zscore_df3 = zscore_df3[zscore_vars].between_time(zscore_vars_start_time, zscore_vars_end_time).dropna().copy()\n",
    "        zscore_df3 = zscore_df3[pd.Series(zscore_df3.index.date, index=zscore_df3.index).isin(valid_dates)]\n",
    "        zscore_df3 = zscore_df3[zscore_df3.index <= pd.to_datetime(bbg_time)]\n",
    "\n",
    "        start_check = pd.to_datetime(zscore_vars_start_time) - timedelta(minutes=7)\n",
    "        start_check = str(start_check.time())\n",
    "        zscore_df = zscore_df.resample(\"10min\", offset=\"5min\").last().ffill().copy()\n",
    "        zscore_df = zscore_df[zscore_vars].between_time(start_check, zscore_vars_end_time).dropna().copy()\n",
    "        zscore_df = zscore_df[pd.Series(zscore_df.index.date, index=zscore_df.index).isin(valid_dates)]\n",
    "        zscore_df = zscore_df[zscore_df.index >= backtest_start_date]\n",
    "        zscore_df = zscore_df[zscore_df.index <= pd.to_datetime(bbg_time)]\n",
    "        \n",
    "        check_later = zscore_df.copy()\n",
    "        sampling_multiplier = len(set(list(check_later.index.time)))\n",
    "        \n",
    "        \n",
    "        ################################## ZScore Calculation Start : Convert Sprd to PX series\n",
    "        \n",
    "        if calc_method == \"Price\":\n",
    "            zscore_df1 = zscore_df.copy()\n",
    "            df = all_dq_dur.copy()\n",
    "            df.columns = df.columns.str.replace(\" Dur\",\"\")\n",
    "            \n",
    "            last_dq_date = df.index[-1]\n",
    "            last_value = df.iloc[-1,0]\n",
    "            \n",
    "            df.loc[ last_dq_date + timedelta(days=1) ] = last_value\n",
    "            df.loc[ last_dq_date + timedelta(days=2) ] = last_value\n",
    "            \n",
    "            df = df.resample(\"1min\").first().ffill().dropna()\n",
    "            dq_dur = df.copy()\n",
    "            \n",
    "            for col in zscore_df1.columns:\n",
    "                if col in dq_dur.columns:\n",
    "                    zscore_df1[f'{col} Dur'] = dq_dur[col]\n",
    "                    zscore_df1[f'{col} Dur'] = zscore_df1[f'{col} Dur'].shift(1)\n",
    "                    zscore_df1[f'Diff {col}'] = zscore_df1[col].diff()\n",
    "                    zscore_df1 = zscore_df1.dropna()\n",
    "                    zscore_df1[f'{col} Daily PX Change'] = -1 * zscore_df1[f'Diff {col}'] * zscore_df1[f'{col} Dur'] *10**(-4)\n",
    "                    zscore_df1[f'{col} Sum PX'] = zscore_df1[f'{col} Daily PX Change'].cumsum()\n",
    "                    zscore_df1[col] = zscore_df1[f'{col} Sum PX']\n",
    "                    zscore_df1 = zscore_df1[zscore_df.columns].copy()\n",
    "        elif calc_method == \"Return\":\n",
    "            zscore_df1 = zscore_df.copy()\n",
    "        \n",
    "        ################################## ZScore Calculation: Differencing and converting to ZScores\n",
    "        \n",
    "        zscore_df = zscore_df1[zscore_df1.index >= backtest_start_date].copy()\n",
    "        \n",
    "        col_list = zscore_df.columns\n",
    "        for period in diff_var:\n",
    "            for col in col_list:\n",
    "                zscore_df[f'{col}_{period}W'] = zscore_df[col].diff(sampling_multiplier*5*period)\n",
    "        \n",
    "        model_lookback = sampling_multiplier*dict_models[model_num][1]\n",
    "        model_lookback_res = sampling_multiplier*dict_models[model_num][2]\n",
    "        \n",
    "        zscore_df = zscore_df.dropna().copy()\n",
    "        zscore_df2 = zscore_df.copy()\n",
    "    \n",
    "        for period in diff_var:\n",
    "            i = len(zscore_df) - model_lookback\n",
    "            reg_Y = zscore_df[[f'{zscore_Y}_{period}W']].iloc[i:i+model_lookback]\n",
    "            reg_X = zscore_df[[item + f\"_{period}W\" for item in zscore_X]].iloc[i:i+model_lookback]                        \n",
    "            model = sm.OLS(reg_Y,sm.add_constant(reg_X)).fit()\n",
    "            # x = (model.resid - model.resid.rolling(model_lookback_res).mean())/model.resid.rolling(model_lookback_res).std()\n",
    "            x = (model.resid - model.resid.mean())/model.resid.std()\n",
    "            zscore_df.loc[zscore_df.index[i+model_lookback-1],f'{period}W_ZScore'] = x.iloc[-1]\n",
    "        \n",
    "        zscore_df['Avg. ZScore'] = zscore_df[[col for col in zscore_df.columns if col.endswith(\"_ZScore\")]].mean(axis=1)\n",
    "        zscore_df = zscore_df[['Avg. ZScore']]\n",
    "    \n",
    "        bt_df = pd.concat([check_later[[model_Y] + model_X],zscore_df],axis=1).dropna()\n",
    "        bt_df = pd.concat([bt_df,beta],axis=1).dropna()\n",
    "        \n",
    "        zplot = bt_df[['Avg. ZScore']].copy()  \n",
    "        zscore_df3 = zscore_df3.dropna()\n",
    "        val += [zscore_df3.index[-1]]\n",
    "        \n",
    "        if calc_method == \"Price\":\n",
    "            if len(model_X)==1:\n",
    "                zplot.columns = [f'{model_Y}({zscore_df3.iloc[-1][model_Y]}) vs. {model_X[0]}({zscore_df3.\\\n",
    "                iloc[-1][model_X[0]]}) ZScore: {zplot.iloc[-1,0]:.2f}']\n",
    "            else:\n",
    "                zplot.columns = [f'{model_Y}({zscore_df3.\\\n",
    "                iloc[-1][model_Y]}) vs. {model_X}({zscore_df3.iloc[-1][model_X[0]]} & {zscore_df3.\\\n",
    "                iloc[-1][model_X[1]]}) ZScore: {zplot.iloc[-1,0]:.2f}']\n",
    "        \n",
    "        elif calc_method == \"Return\":\n",
    "            \n",
    "            px_sprd_ref = bbg_datafile.iloc[-9000:].copy()\n",
    "            px_sprd_ref = px_sprd_ref.resample(\"1min\").last().ffill().sort_index().copy()\n",
    "            \n",
    "            if len(model_X)==1:\n",
    "                zplot.columns = [f'{model_Y}({px_sprd_ref.loc[zscore_df3.index[-1], model_Y]}) vs. {model_X[0]}({px_sprd_ref.\\\n",
    "                    loc[zscore_df3.index[-1], model_X[0]]}) ZScore: {zplot.iloc[-1,0]:.2f}']\n",
    "            else:\n",
    "                zplot.columns = [f'{model_Y}({px_sprd_ref.\\\n",
    "                    loc[zscore_df3.index[-1], model_Y]}) vs. {model_X}({px_sprd_ref.loc[zscore_df3.index[-1], model_X[0]]} & {px_sprd_ref.\\\n",
    "                    loc[zscore_df3.index[-1], model_X[1]]}) ZScore: {zplot.iloc[-1,0]:.2f}']\n",
    "\n",
    "        all_zplots = pd.concat([all_zplots, zplot],axis=1)\n",
    "        zplot = all_zplots.copy()\n",
    "    return zplot, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548e4771-c543-40df-a1f6-3432d068c63a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_29ed5_row0_col4 {\n",
       "  background-color: rgba(129,204,167,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row0_col5 {\n",
       "  background-color: rgba(195,231,213,0.75);\n",
       "}\n",
       "#T_29ed5_row1_col4 {\n",
       "  background-color: rgba(236,247,241,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row1_col5 {\n",
       "  background-color: rgba(248,224,219,0.75);\n",
       "}\n",
       "#T_29ed5_row2_col0, #T_29ed5_row2_col1, #T_29ed5_row2_col2, #T_29ed5_row2_col3, #T_29ed5_row2_col6, #T_29ed5_row2_col7, #T_29ed5_row7_col0, #T_29ed5_row7_col1, #T_29ed5_row7_col2, #T_29ed5_row7_col3, #T_29ed5_row7_col6, #T_29ed5_row7_col7, #T_29ed5_row13_col0, #T_29ed5_row13_col1, #T_29ed5_row13_col2, #T_29ed5_row13_col3, #T_29ed5_row13_col6, #T_29ed5_row13_col7, #T_29ed5_row15_col0, #T_29ed5_row15_col1, #T_29ed5_row15_col2, #T_29ed5_row15_col3, #T_29ed5_row15_col6, #T_29ed5_row15_col7, #T_29ed5_row17_col0, #T_29ed5_row17_col1, #T_29ed5_row17_col2, #T_29ed5_row17_col3, #T_29ed5_row17_col6, #T_29ed5_row17_col7, #T_29ed5_row21_col0, #T_29ed5_row21_col1, #T_29ed5_row21_col2, #T_29ed5_row21_col3, #T_29ed5_row21_col6, #T_29ed5_row21_col7 {\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row2_col4 {\n",
       "  background-color: rgba(87,187,138,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row2_col5 {\n",
       "  background-color: rgba(156,215,186,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row3_col4 {\n",
       "  background-color: rgba(130,204,168,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row3_col5 {\n",
       "  background-color: rgba(142,209,176,0.75);\n",
       "}\n",
       "#T_29ed5_row4_col4 {\n",
       "  background-color: rgba(124,202,164,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row4_col5 {\n",
       "  background-color: rgba(139,208,174,0.75);\n",
       "}\n",
       "#T_29ed5_row5_col4 {\n",
       "  background-color: rgba(178,223,201,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row5_col5 {\n",
       "  background-color: rgba(254,254,253,0.75);\n",
       "}\n",
       "#T_29ed5_row6_col4 {\n",
       "  background-color: rgba(186,227,207,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row6_col5 {\n",
       "  background-color: rgba(192,229,211,0.75);\n",
       "}\n",
       "#T_29ed5_row7_col4 {\n",
       "  background-color: rgba(170,220,195,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row7_col5 {\n",
       "  background-color: rgba(185,226,206,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row8_col4 {\n",
       "  background-color: rgba(254,254,254,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row8_col5 {\n",
       "  background-color: rgba(146,210,179,0.75);\n",
       "}\n",
       "#T_29ed5_row9_col4 {\n",
       "  background-color: rgba(252,254,253,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row9_col5 {\n",
       "  background-color: rgba(143,209,177,0.75);\n",
       "}\n",
       "#T_29ed5_row10_col4 {\n",
       "  background-color: rgba(230,139,120,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row10_col5 {\n",
       "  background-color: rgba(250,232,229,0.75);\n",
       "}\n",
       "#T_29ed5_row11_col4 {\n",
       "  background-color: rgba(230,135,115,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row11_col5 {\n",
       "  background-color: rgba(205,234,220,0.75);\n",
       "}\n",
       "#T_29ed5_row12_col4 {\n",
       "  background-color: rgba(249,230,226,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row12_col5 {\n",
       "  background-color: rgba(87,187,138,0.75);\n",
       "}\n",
       "#T_29ed5_row13_col4 {\n",
       "  background-color: rgba(240,187,176,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row13_col5 {\n",
       "  background-color: rgba(139,208,174,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row14_col4 {\n",
       "  background-color: rgba(137,207,173,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row14_col5 {\n",
       "  background-color: rgba(240,249,245,0.75);\n",
       "}\n",
       "#T_29ed5_row15_col4 {\n",
       "  background-color: rgba(167,219,193,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row15_col5 {\n",
       "  background-color: rgba(250,233,230,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row16_col4 {\n",
       "  background-color: rgba(254,252,252,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row16_col5 {\n",
       "  background-color: rgba(252,240,238,0.75);\n",
       "}\n",
       "#T_29ed5_row17_col4 {\n",
       "  background-color: rgba(174,222,198,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row17_col5 {\n",
       "  background-color: rgba(241,190,179,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row18_col4 {\n",
       "  background-color: rgba(246,251,249,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row18_col5 {\n",
       "  background-color: rgba(247,219,213,0.75);\n",
       "}\n",
       "#T_29ed5_row19_col4 {\n",
       "  background-color: rgba(248,224,219,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row19_col5 {\n",
       "  background-color: rgba(230,135,115,0.75);\n",
       "}\n",
       "#T_29ed5_row20_col4 {\n",
       "  background-color: rgba(210,236,223,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_29ed5_row20_col5 {\n",
       "  background-color: rgba(251,235,232,0.75);\n",
       "}\n",
       "#T_29ed5_row21_col4 {\n",
       "  background-color: rgba(155,214,185,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_29ed5_row21_col5 {\n",
       "  background-color: rgba(173,221,198,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_29ed5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_29ed5_level0_col0\" class=\"col_heading level0 col0\" colspan=\"8\">04:06 PM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29ed5_level1_col0\" class=\"col_heading level1 col0\" >Long Risk</th>\n",
       "      <th id=\"T_29ed5_level1_col1\" class=\"col_heading level1 col1\" >Ref</th>\n",
       "      <th id=\"T_29ed5_level1_col2\" class=\"col_heading level1 col2\" >Short Risk</th>\n",
       "      <th id=\"T_29ed5_level1_col3\" class=\"col_heading level1 col3\" >Ref.</th>\n",
       "      <th id=\"T_29ed5_level1_col4\" class=\"col_heading level1 col4\" >PX_Zscore 1/2/3w</th>\n",
       "      <th id=\"T_29ed5_level1_col5\" class=\"col_heading level1 col5\" >Rtn_Zscore 6/9/12w</th>\n",
       "      <th id=\"T_29ed5_level1_col6\" class=\"col_heading level1 col6\" >Valuation</th>\n",
       "      <th id=\"T_29ed5_level1_col7\" class=\"col_heading level1 col7\" >Last Update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row0_col0\" class=\"data row0 col0\" >IG</td>\n",
       "      <td id=\"T_29ed5_row0_col1\" class=\"data row0 col1\" >53.47</td>\n",
       "      <td id=\"T_29ed5_row0_col2\" class=\"data row0 col2\" >['VCIT', 'IEF']</td>\n",
       "      <td id=\"T_29ed5_row0_col3\" class=\"data row0 col3\" >['83.87', '96.28']</td>\n",
       "      <td id=\"T_29ed5_row0_col4\" class=\"data row0 col4\" >-2.19</td>\n",
       "      <td id=\"T_29ed5_row0_col5\" class=\"data row0 col5\" >-0.50</td>\n",
       "      <td id=\"T_29ed5_row0_col6\" class=\"data row0 col6\" >IG cheap to ['VCIT', 'IEF']</td>\n",
       "      <td id=\"T_29ed5_row0_col7\" class=\"data row0 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row1_col0\" class=\"data row1 col0\" >HY</td>\n",
       "      <td id=\"T_29ed5_row1_col1\" class=\"data row1 col1\" >107.602</td>\n",
       "      <td id=\"T_29ed5_row1_col2\" class=\"data row1 col2\" >['HYG', 'IEI']</td>\n",
       "      <td id=\"T_29ed5_row1_col3\" class=\"data row1 col3\" >['80.92', '119.31']</td>\n",
       "      <td id=\"T_29ed5_row1_col4\" class=\"data row1 col4\" >-0.33</td>\n",
       "      <td id=\"T_29ed5_row1_col5\" class=\"data row1 col5\" >0.32</td>\n",
       "      <td id=\"T_29ed5_row1_col6\" class=\"data row1 col6\" >HY cheap to ['HYG', 'IEI']</td>\n",
       "      <td id=\"T_29ed5_row1_col7\" class=\"data row1 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row2_col0\" class=\"data row2 col0\" >EM</td>\n",
       "      <td id=\"T_29ed5_row2_col1\" class=\"data row2 col1\" >97.752</td>\n",
       "      <td id=\"T_29ed5_row2_col2\" class=\"data row2 col2\" >['EMB', 'IEF']</td>\n",
       "      <td id=\"T_29ed5_row2_col3\" class=\"data row2 col3\" >['95.26', '96.28']</td>\n",
       "      <td id=\"T_29ed5_row2_col4\" class=\"data row2 col4\" >-2.93</td>\n",
       "      <td id=\"T_29ed5_row2_col5\" class=\"data row2 col5\" >-0.83</td>\n",
       "      <td id=\"T_29ed5_row2_col6\" class=\"data row2 col6\" >EM cheap to ['EMB', 'IEF']</td>\n",
       "      <td id=\"T_29ed5_row2_col7\" class=\"data row2 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row3_col0\" class=\"data row3 col0\" >IG</td>\n",
       "      <td id=\"T_29ed5_row3_col1\" class=\"data row3 col1\" >53.44788</td>\n",
       "      <td id=\"T_29ed5_row3_col2\" class=\"data row3 col2\" >ESA</td>\n",
       "      <td id=\"T_29ed5_row3_col3\" class=\"data row3 col3\" >658.06</td>\n",
       "      <td id=\"T_29ed5_row3_col4\" class=\"data row3 col4\" >-2.17</td>\n",
       "      <td id=\"T_29ed5_row3_col5\" class=\"data row3 col5\" >-0.95</td>\n",
       "      <td id=\"T_29ed5_row3_col6\" class=\"data row3 col6\" >IG cheap to ESA</td>\n",
       "      <td id=\"T_29ed5_row3_col7\" class=\"data row3 col7\" >25-Sep 04:06 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row4_col0\" class=\"data row4 col0\" >IG</td>\n",
       "      <td id=\"T_29ed5_row4_col1\" class=\"data row4 col1\" >53.47</td>\n",
       "      <td id=\"T_29ed5_row4_col2\" class=\"data row4 col2\" >SPY</td>\n",
       "      <td id=\"T_29ed5_row4_col3\" class=\"data row4 col3\" >658.05</td>\n",
       "      <td id=\"T_29ed5_row4_col4\" class=\"data row4 col4\" >-2.27</td>\n",
       "      <td id=\"T_29ed5_row4_col5\" class=\"data row4 col5\" >-0.98</td>\n",
       "      <td id=\"T_29ed5_row4_col6\" class=\"data row4 col6\" >IG cheap to SPY</td>\n",
       "      <td id=\"T_29ed5_row4_col7\" class=\"data row4 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row5_col0\" class=\"data row5 col0\" >IG</td>\n",
       "      <td id=\"T_29ed5_row5_col1\" class=\"data row5 col1\" >53.47</td>\n",
       "      <td id=\"T_29ed5_row5_col2\" class=\"data row5 col2\" >RSP</td>\n",
       "      <td id=\"T_29ed5_row5_col3\" class=\"data row5 col3\" >186.72</td>\n",
       "      <td id=\"T_29ed5_row5_col4\" class=\"data row5 col4\" >-1.34</td>\n",
       "      <td id=\"T_29ed5_row5_col5\" class=\"data row5 col5\" >0.01</td>\n",
       "      <td id=\"T_29ed5_row5_col6\" class=\"data row5 col6\" >IG cheap to RSP</td>\n",
       "      <td id=\"T_29ed5_row5_col7\" class=\"data row5 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row6_col0\" class=\"data row6 col0\" >IG</td>\n",
       "      <td id=\"T_29ed5_row6_col1\" class=\"data row6 col1\" >53.47</td>\n",
       "      <td id=\"T_29ed5_row6_col2\" class=\"data row6 col2\" >IJH</td>\n",
       "      <td id=\"T_29ed5_row6_col3\" class=\"data row6 col3\" >64.68</td>\n",
       "      <td id=\"T_29ed5_row6_col4\" class=\"data row6 col4\" >-1.20</td>\n",
       "      <td id=\"T_29ed5_row6_col5\" class=\"data row6 col5\" >-0.53</td>\n",
       "      <td id=\"T_29ed5_row6_col6\" class=\"data row6 col6\" >IG cheap to IJH</td>\n",
       "      <td id=\"T_29ed5_row6_col7\" class=\"data row6 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row7_col0\" class=\"data row7 col0\" >IG</td>\n",
       "      <td id=\"T_29ed5_row7_col1\" class=\"data row7 col1\" >53.47</td>\n",
       "      <td id=\"T_29ed5_row7_col2\" class=\"data row7 col2\" >IG Eqty</td>\n",
       "      <td id=\"T_29ed5_row7_col3\" class=\"data row7 col3\" >203.66</td>\n",
       "      <td id=\"T_29ed5_row7_col4\" class=\"data row7 col4\" >-1.48</td>\n",
       "      <td id=\"T_29ed5_row7_col5\" class=\"data row7 col5\" >-0.59</td>\n",
       "      <td id=\"T_29ed5_row7_col6\" class=\"data row7 col6\" >IG cheap to IG Eqty</td>\n",
       "      <td id=\"T_29ed5_row7_col7\" class=\"data row7 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row8_col0\" class=\"data row8 col0\" >HY</td>\n",
       "      <td id=\"T_29ed5_row8_col1\" class=\"data row8 col1\" >107.6124</td>\n",
       "      <td id=\"T_29ed5_row8_col2\" class=\"data row8 col2\" >ESA</td>\n",
       "      <td id=\"T_29ed5_row8_col3\" class=\"data row8 col3\" >658.06</td>\n",
       "      <td id=\"T_29ed5_row8_col4\" class=\"data row8 col4\" >-0.01</td>\n",
       "      <td id=\"T_29ed5_row8_col5\" class=\"data row8 col5\" >-0.92</td>\n",
       "      <td id=\"T_29ed5_row8_col6\" class=\"data row8 col6\" >HY cheap to ESA</td>\n",
       "      <td id=\"T_29ed5_row8_col7\" class=\"data row8 col7\" >25-Sep 04:06 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row9_col0\" class=\"data row9 col0\" >HY</td>\n",
       "      <td id=\"T_29ed5_row9_col1\" class=\"data row9 col1\" >107.602</td>\n",
       "      <td id=\"T_29ed5_row9_col2\" class=\"data row9 col2\" >SPY</td>\n",
       "      <td id=\"T_29ed5_row9_col3\" class=\"data row9 col3\" >658.05</td>\n",
       "      <td id=\"T_29ed5_row9_col4\" class=\"data row9 col4\" >-0.04</td>\n",
       "      <td id=\"T_29ed5_row9_col5\" class=\"data row9 col5\" >-0.94</td>\n",
       "      <td id=\"T_29ed5_row9_col6\" class=\"data row9 col6\" >HY cheap to SPY</td>\n",
       "      <td id=\"T_29ed5_row9_col7\" class=\"data row9 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row10_col0\" class=\"data row10 col0\" >HY</td>\n",
       "      <td id=\"T_29ed5_row10_col1\" class=\"data row10 col1\" >107.602</td>\n",
       "      <td id=\"T_29ed5_row10_col2\" class=\"data row10 col2\" >RSP</td>\n",
       "      <td id=\"T_29ed5_row10_col3\" class=\"data row10 col3\" >186.72</td>\n",
       "      <td id=\"T_29ed5_row10_col4\" class=\"data row10 col4\" >1.03</td>\n",
       "      <td id=\"T_29ed5_row10_col5\" class=\"data row10 col5\" >0.23</td>\n",
       "      <td id=\"T_29ed5_row10_col6\" class=\"data row10 col6\" >HY rich to RSP</td>\n",
       "      <td id=\"T_29ed5_row10_col7\" class=\"data row10 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row11_col0\" class=\"data row11 col0\" >HY</td>\n",
       "      <td id=\"T_29ed5_row11_col1\" class=\"data row11 col1\" >107.602</td>\n",
       "      <td id=\"T_29ed5_row11_col2\" class=\"data row11 col2\" >IJH</td>\n",
       "      <td id=\"T_29ed5_row11_col3\" class=\"data row11 col3\" >64.68</td>\n",
       "      <td id=\"T_29ed5_row11_col4\" class=\"data row11 col4\" >1.07</td>\n",
       "      <td id=\"T_29ed5_row11_col5\" class=\"data row11 col5\" >-0.42</td>\n",
       "      <td id=\"T_29ed5_row11_col6\" class=\"data row11 col6\" >HY rich to IJH</td>\n",
       "      <td id=\"T_29ed5_row11_col7\" class=\"data row11 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row12_col0\" class=\"data row12 col0\" >HY</td>\n",
       "      <td id=\"T_29ed5_row12_col1\" class=\"data row12 col1\" >107.602</td>\n",
       "      <td id=\"T_29ed5_row12_col2\" class=\"data row12 col2\" >IWM</td>\n",
       "      <td id=\"T_29ed5_row12_col3\" class=\"data row12 col3\" >239.31</td>\n",
       "      <td id=\"T_29ed5_row12_col4\" class=\"data row12 col4\" >0.22</td>\n",
       "      <td id=\"T_29ed5_row12_col5\" class=\"data row12 col5\" >-1.42</td>\n",
       "      <td id=\"T_29ed5_row12_col6\" class=\"data row12 col6\" >HY rich to IWM</td>\n",
       "      <td id=\"T_29ed5_row12_col7\" class=\"data row12 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row13_col0\" class=\"data row13 col0\" >HY</td>\n",
       "      <td id=\"T_29ed5_row13_col1\" class=\"data row13 col1\" >107.602</td>\n",
       "      <td id=\"T_29ed5_row13_col2\" class=\"data row13 col2\" >HY Eqty</td>\n",
       "      <td id=\"T_29ed5_row13_col3\" class=\"data row13 col3\" >328.58</td>\n",
       "      <td id=\"T_29ed5_row13_col4\" class=\"data row13 col4\" >0.60</td>\n",
       "      <td id=\"T_29ed5_row13_col5\" class=\"data row13 col5\" >-0.98</td>\n",
       "      <td id=\"T_29ed5_row13_col6\" class=\"data row13 col6\" >HY rich to HY Eqty</td>\n",
       "      <td id=\"T_29ed5_row13_col7\" class=\"data row13 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row14_col0\" class=\"data row14 col0\" >MAIN</td>\n",
       "      <td id=\"T_29ed5_row14_col1\" class=\"data row14 col1\" >56.823</td>\n",
       "      <td id=\"T_29ed5_row14_col2\" class=\"data row14 col2\" >SX5E</td>\n",
       "      <td id=\"T_29ed5_row14_col3\" class=\"data row14 col3\" >5444.89</td>\n",
       "      <td id=\"T_29ed5_row14_col4\" class=\"data row14 col4\" >-2.05</td>\n",
       "      <td id=\"T_29ed5_row14_col5\" class=\"data row14 col5\" >-0.12</td>\n",
       "      <td id=\"T_29ed5_row14_col6\" class=\"data row14 col6\" >MAIN cheap to SX5E</td>\n",
       "      <td id=\"T_29ed5_row14_col7\" class=\"data row14 col7\" >25-Sep 11:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row15_col0\" class=\"data row15 col0\" >XOVER</td>\n",
       "      <td id=\"T_29ed5_row15_col1\" class=\"data row15 col1\" >268.184</td>\n",
       "      <td id=\"T_29ed5_row15_col2\" class=\"data row15 col2\" >SX5E</td>\n",
       "      <td id=\"T_29ed5_row15_col3\" class=\"data row15 col3\" >5444.89</td>\n",
       "      <td id=\"T_29ed5_row15_col4\" class=\"data row15 col4\" >-1.53</td>\n",
       "      <td id=\"T_29ed5_row15_col5\" class=\"data row15 col5\" >0.22</td>\n",
       "      <td id=\"T_29ed5_row15_col6\" class=\"data row15 col6\" >XOVER cheap to SX5E</td>\n",
       "      <td id=\"T_29ed5_row15_col7\" class=\"data row15 col7\" >25-Sep 11:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row16_col0\" class=\"data row16 col0\" >MAIN</td>\n",
       "      <td id=\"T_29ed5_row16_col1\" class=\"data row16 col1\" >56.823</td>\n",
       "      <td id=\"T_29ed5_row16_col2\" class=\"data row16 col2\" >IG</td>\n",
       "      <td id=\"T_29ed5_row16_col3\" class=\"data row16 col3\" >53.181</td>\n",
       "      <td id=\"T_29ed5_row16_col4\" class=\"data row16 col4\" >0.02</td>\n",
       "      <td id=\"T_29ed5_row16_col5\" class=\"data row16 col5\" >0.15</td>\n",
       "      <td id=\"T_29ed5_row16_col6\" class=\"data row16 col6\" >MAIN rich to IG</td>\n",
       "      <td id=\"T_29ed5_row16_col7\" class=\"data row16 col7\" >25-Sep 11:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row17_col0\" class=\"data row17 col0\" >XOVER</td>\n",
       "      <td id=\"T_29ed5_row17_col1\" class=\"data row17 col1\" >268.184</td>\n",
       "      <td id=\"T_29ed5_row17_col2\" class=\"data row17 col2\" >HY</td>\n",
       "      <td id=\"T_29ed5_row17_col3\" class=\"data row17 col3\" >107.63</td>\n",
       "      <td id=\"T_29ed5_row17_col4\" class=\"data row17 col4\" >-1.41</td>\n",
       "      <td id=\"T_29ed5_row17_col5\" class=\"data row17 col5\" >0.67</td>\n",
       "      <td id=\"T_29ed5_row17_col6\" class=\"data row17 col6\" >XOVER cheap to HY</td>\n",
       "      <td id=\"T_29ed5_row17_col7\" class=\"data row17 col7\" >25-Sep 11:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row18_col0\" class=\"data row18 col0\" >EMB</td>\n",
       "      <td id=\"T_29ed5_row18_col1\" class=\"data row18 col1\" >95.26</td>\n",
       "      <td id=\"T_29ed5_row18_col2\" class=\"data row18 col2\" >EEM</td>\n",
       "      <td id=\"T_29ed5_row18_col3\" class=\"data row18 col3\" >52.81</td>\n",
       "      <td id=\"T_29ed5_row18_col4\" class=\"data row18 col4\" >-0.14</td>\n",
       "      <td id=\"T_29ed5_row18_col5\" class=\"data row18 col5\" >0.37</td>\n",
       "      <td id=\"T_29ed5_row18_col6\" class=\"data row18 col6\" >EMB cheap to EEM</td>\n",
       "      <td id=\"T_29ed5_row18_col7\" class=\"data row18 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row19_col0\" class=\"data row19 col0\" >EM</td>\n",
       "      <td id=\"T_29ed5_row19_col1\" class=\"data row19 col1\" >97.75198</td>\n",
       "      <td id=\"T_29ed5_row19_col2\" class=\"data row19 col2\" >IG</td>\n",
       "      <td id=\"T_29ed5_row19_col3\" class=\"data row19 col3\" >53.44788</td>\n",
       "      <td id=\"T_29ed5_row19_col4\" class=\"data row19 col4\" >0.27</td>\n",
       "      <td id=\"T_29ed5_row19_col5\" class=\"data row19 col5\" >1.25</td>\n",
       "      <td id=\"T_29ed5_row19_col6\" class=\"data row19 col6\" >EM rich to IG</td>\n",
       "      <td id=\"T_29ed5_row19_col7\" class=\"data row19 col7\" >25-Sep 04:06 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row20_col0\" class=\"data row20 col0\" >EM</td>\n",
       "      <td id=\"T_29ed5_row20_col1\" class=\"data row20 col1\" >97.783</td>\n",
       "      <td id=\"T_29ed5_row20_col2\" class=\"data row20 col2\" >XOVER</td>\n",
       "      <td id=\"T_29ed5_row20_col3\" class=\"data row20 col3\" >268.184</td>\n",
       "      <td id=\"T_29ed5_row20_col4\" class=\"data row20 col4\" >-0.78</td>\n",
       "      <td id=\"T_29ed5_row20_col5\" class=\"data row20 col5\" >0.20</td>\n",
       "      <td id=\"T_29ed5_row20_col6\" class=\"data row20 col6\" >EM cheap to XOVER</td>\n",
       "      <td id=\"T_29ed5_row20_col7\" class=\"data row20 col7\" >25-Sep 11:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29ed5_row21_col0\" class=\"data row21 col0\" >EM</td>\n",
       "      <td id=\"T_29ed5_row21_col1\" class=\"data row21 col1\" >97.752</td>\n",
       "      <td id=\"T_29ed5_row21_col2\" class=\"data row21 col2\" >EEM</td>\n",
       "      <td id=\"T_29ed5_row21_col3\" class=\"data row21 col3\" >52.81</td>\n",
       "      <td id=\"T_29ed5_row21_col4\" class=\"data row21 col4\" >-1.73</td>\n",
       "      <td id=\"T_29ed5_row21_col5\" class=\"data row21 col5\" >-0.69</td>\n",
       "      <td id=\"T_29ed5_row21_col6\" class=\"data row21 col6\" >EM cheap to EEM</td>\n",
       "      <td id=\"T_29ed5_row21_col7\" class=\"data row21 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x205a696c9e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     91\u001b[39m times_list += t1\n\u001b[32m     93\u001b[39m models_list = [ \n\u001b[32m     94\u001b[39m     [\u001b[33m'\u001b[39m\u001b[33mCDX EM 5Y\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33mEMB\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mIEF\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mCDX EM 5Y\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33mEMB\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mIEF\u001b[39m\u001b[33m'\u001b[39m],],\n\u001b[32m     95\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m l1, t1 = \u001b[43mx_model\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m l2 = pd.concat([l2,l1],axis=\u001b[32m1\u001b[39m)\n\u001b[32m     98\u001b[39m times_list += t1\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mx_model\u001b[39m\u001b[34m(model_num, models_list, diff_var, calc_method)\u001b[39m\n\u001b[32m    117\u001b[39m df.loc[ last_dq_date + timedelta(days=\u001b[32m1\u001b[39m) ] = last_value\n\u001b[32m    118\u001b[39m df.loc[ last_dq_date + timedelta(days=\u001b[32m2\u001b[39m) ] = last_value\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1min\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mffill\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m dq_dur = df.copy()\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m zscore_df1.columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:6678\u001b[39m, in \u001b[36mDataFrame.dropna\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6675\u001b[39m     mask = count >= thresh\n\u001b[32m   6676\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m how == \u001b[33m\"\u001b[39m\u001b[33many\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   6677\u001b[39m     \u001b[38;5;66;03m# faster equivalent to 'agg_obj.count(agg_axis) == self.shape[agg_axis]'\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6678\u001b[39m     mask = \u001b[43mnotna\u001b[49m\u001b[43m(\u001b[49m\u001b[43magg_obj\u001b[49m\u001b[43m)\u001b[49m.all(axis=agg_axis, bool_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   6679\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m how == \u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   6680\u001b[39m     \u001b[38;5;66;03m# faster equivalent to 'agg_obj.count(agg_axis) > 0'\u001b[39;00m\n\u001b[32m   6681\u001b[39m     mask = notna(agg_obj).any(axis=agg_axis, bool_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:457\u001b[39m, in \u001b[36mnotna\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mnotna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m | npt.NDArray[np.bool_] | NDFrame:\n\u001b[32m    381\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[33;03m    Detect non-missing values for an array-like object.\u001b[39;00m\n\u001b[32m    383\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    455\u001b[39m \u001b[33;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[32m    456\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m     res = \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m    459\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:178\u001b[39m, in \u001b[36misna\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m | npt.NDArray[np.bool_] | NDFrame:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m \u001b[33;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:221\u001b[39m, in \u001b[36m_isna\u001b[39m\u001b[34m(obj, inf_as_na)\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCDataFrame):\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _isna_array(np.asarray(obj, dtype=\u001b[38;5;28mobject\u001b[39m), inf_as_na=inf_as_na)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:6490\u001b[39m, in \u001b[36mDataFrame.isna\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   6488\u001b[39m \u001b[38;5;129m@doc\u001b[39m(NDFrame.isna, klass=_shared_doc_kwargs[\u001b[33m\"\u001b[39m\u001b[33mklass\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   6489\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34misna\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame:\n\u001b[32m-> \u001b[39m\u001b[32m6490\u001b[39m     res_mgr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43misna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6491\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(res_mgr, axes=res_mgr.axes)\n\u001b[32m   6492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33misna\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\base.py:178\u001b[39m, in \u001b[36mDataManager.isna\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34misna\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) -> Self:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapply\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[39m, in \u001b[36mBlock.apply\u001b[39m\u001b[34m(self, func, **kwargs)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, **kwargs) -> \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[32m    389\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[33;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[33;03m    one\u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m     result = maybe_coerce_values(result)\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._split_op_result(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:178\u001b[39m, in \u001b[36misna\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m | npt.NDArray[np.bool_] | NDFrame:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m \u001b[33;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:207\u001b[39m, in \u001b[36m_isna\u001b[39m\u001b[34m(obj, inf_as_na)\u001b[39m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np.ndarray, ABCExtensionArray)):\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj._can_hold_na:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:300\u001b[39m, in \u001b[36m_isna_array\u001b[39m\u001b[34m(values, inf_as_na)\u001b[39m\n\u001b[32m    298\u001b[39m         result = ~np.isfinite(values)\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m         result = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "display(None, display_id=\"DFA\")\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ################################################################## Capture PX; check if market is live and attach\n",
    "    px = blp.bdp(tickers=all_bbg_tickers, flds='PX_LAST').T\n",
    "    bbg_time = datetime.now()\n",
    "    px.index= [f'{bbg_time}']\n",
    "    px.index = pd.to_datetime(px.index)\n",
    "    px = px.resample(\"1min\").last()\n",
    "    px.loc[px.index[0],'ESA INDEX'] = round(blp.bdp(tickers=\"ESA INDEX\", flds=\"PX_LAST\").iloc[0,0] * (spx_val/esa_val),2)\n",
    "    \n",
    "    if first_current_date_esa_close or bbg_time <= pd.to_datetime(\"09:33:00\"):\n",
    "        live_list = ['CDX IG CDSI GEN 5Y CORP','ITRX EUR CDSI GEN 5Y CORP', 'RSP US EQUITY','SX5E INDEX','ESA INDEX']\n",
    "        mkt_live = blp.bdh(tickers=live_list, flds='px_last', start_date = datetime.now()-timedelta(days=5))\n",
    "        mkt_live.columns = live_list\n",
    "        first_current_date_esa_close = False\n",
    "    \n",
    "    for col in px.columns:\n",
    "        if col == \"ESA INDEX\" and bbg_time.date() in mkt_live[live_dict[col]].dropna().index:\n",
    "            if bbg_time.time() >= pd.to_datetime(\"07:30\").time() and\\\n",
    "            bbg_time.time() <= (pd.to_datetime(\"20:00\") + timedelta(minutes=1)).time():\n",
    "                continue\n",
    "            else:\n",
    "                px.loc[px.index[0],col] = np.nan\n",
    "        elif bbg_time.date() in mkt_live[live_dict[col]].dropna().index and\\\n",
    "        bbg_time.time() >= pd.to_datetime(dict_map[reverse_dict[col]][1]).time() and\\\n",
    "        bbg_time.time() <= (pd.to_datetime(dict_map[reverse_dict[col]][2]) + timedelta(minutes=1)).time():\n",
    "            continue\n",
    "        else:\n",
    "            px.loc[px.index[0],col] = np.nan\n",
    "    px.columns = [reverse_dict[item] for item in px.columns]\n",
    "    bbg_datafile = pd.concat([bbg_datafile, px]).sort_index().copy()\n",
    "    bbg_datafile = bbg_datafile.resample(\"1min\").last().dropna(how='all').copy()\n",
    "\n",
    "    ################################################################## Convert PX to ER series and attach\n",
    "    current_er_series = None\n",
    "\n",
    "    for col in px.columns:\n",
    "        carry_days = (datetime.now() - pd.to_datetime(last_dict[col][2])).days\n",
    "        x = px[[col]].dropna().copy()\n",
    "\n",
    "        first_run = False\n",
    "        if col==\"ESA\":\n",
    "            first_run = True\n",
    "        elif dict_map[col][0] == \"Eq\":\n",
    "            first_run = True\n",
    "            \n",
    "        if first_run:\n",
    "            rate = funding[[item for item in funding.columns if col == item.split(\" \",2)[2].rsplit(\" \",1)[0]]].dropna().iloc[-1]\n",
    "            rate = rate.mean()   ############ etf funding rate\n",
    "            x = (last_dict[col][0])*((x/last_dict[col][1])-(rate/100)*(carry_days/360))\n",
    "        elif dict_map[col][4] == \"Yes\":\n",
    "            x = (last_dict[col][0])*(1 - dur[f'{col}_dq_dur'].iloc[-1]*(x-last_dict[col][1])*(10**(-4))+(dict_map[col][3]/100)*(carry_days/360))\n",
    "        elif dict_map[col][0] == \"CDX\":\n",
    "            x = (last_dict[col][0])*(1 + (x-last_dict[col][1])*(10**(-2))+(dict_map[col][3]/100)*(carry_days/360))\n",
    "        \n",
    "        current_er_series = pd.concat([current_er_series, x], axis=1)\n",
    "    all_intraday_er_series = pd.concat([all_intraday_er_series, current_er_series]).sort_index().copy()\n",
    "    all_intraday_er_series = all_intraday_er_series.resample(\"1min\").last().dropna(how='all').copy()\n",
    "    \n",
    "    last_update_time = all_intraday_er_series.copy()\n",
    "    \n",
    "    ##################################################################  Regressions starts from here\n",
    "    all_zscore_values = []\n",
    "\n",
    "    for diff_list in [[1,2,3],[6,9,12]]:        \n",
    "        times_list = []\n",
    "\n",
    "        if diff_list == [1,2,3]:\n",
    "            calc = \"Price\"\n",
    "        elif diff_list == [6,9,12]:\n",
    "            calc = \"Return\"            \n",
    "        \n",
    "        # model_Y, model_X (specify as a list) ### We trade these\n",
    "        # zscore_Y, zscore_X (specify as a list) ### We use these only for generating the zscore; names are taken from BBG datafile\n",
    "        \n",
    "        models_list = [\n",
    "            ['CDX IG 5Y', ['VCIT','IEF'], 'CDX IG 5Y', ['VCIT','IEF'],],\n",
    "        ]\n",
    "        l1, t1 = x_model(3, models_list, diff_list, calc)\n",
    "        l2 = l1.copy()\n",
    "        times_list += t1\n",
    "           \n",
    "        models_list = [ \n",
    "            ['CDX HY 5Y', ['HYG','IEI'], 'CDX HY 5Y', ['HYG','IEI'],],\n",
    "            \n",
    "        ]\n",
    "        l1, t1 = x_model(3, models_list, diff_list, calc)\n",
    "        l2 = pd.concat([l2,l1],axis=1)\n",
    "        times_list += t1\n",
    "        \n",
    "        models_list = [ \n",
    "            ['CDX EM 5Y', ['EMB','IEF'], 'CDX EM 5Y', ['EMB','IEF'],],\n",
    "        ]\n",
    "        l1, t1 = x_model(3, models_list, diff_list, calc)\n",
    "        l2 = pd.concat([l2,l1],axis=1)\n",
    "        times_list += t1\n",
    "        \n",
    "        models_list = [ \n",
    "        \n",
    "            ['CDX IG 5Y', ['ESA'], 'CDX IG 5Y', ['ESA'],],\n",
    "            ['CDX IG 5Y', ['SPY'], 'CDX IG 5Y', ['SPY'],],\n",
    "            ['CDX IG 5Y', ['RSP'], 'CDX IG 5Y', ['RSP'],],\n",
    "            ['CDX IG 5Y', ['IJH'], 'CDX IG 5Y', ['IJH'],],\n",
    "            ['CDX IG 5Y', ['IG Eqty'], 'CDX IG 5Y', ['IG Eqty'],],\n",
    "            \n",
    "            ['CDX HY 5Y', ['ESA'], 'CDX HY 5Y', ['ESA'],],\n",
    "            ['CDX HY 5Y', ['SPY'], 'CDX HY 5Y', ['SPY'],],\n",
    "            ['CDX HY 5Y', ['RSP'], 'CDX HY 5Y', ['RSP'],],\n",
    "            ['CDX HY 5Y', ['IJH'], 'CDX HY 5Y', ['IJH'],],\n",
    "            # ['CDX HY 5Y', ['RTY'], 'CDX HY 5Y', ['RTY'],],\n",
    "            ['CDX HY 5Y', ['IWM'], 'CDX HY 5Y', ['IWM'],],\n",
    "            ['CDX HY 5Y', ['HY Eqty'], 'CDX HY 5Y', ['HY Eqty'],],\n",
    "            \n",
    "            ['ITRX MAIN 5Y', ['SX5E'], 'ITRX MAIN 5Y', ['SX5E'], ],\n",
    "            ['ITRX XOVER 5Y', ['SX5E'], 'ITRX XOVER 5Y', ['SX5E'], ],\n",
    "            \n",
    "            ['ITRX MAIN 5Y', ['CDX IG 5Y'], 'ITRX MAIN 5Y', ['CDX IG 5Y'],],\n",
    "            ['ITRX XOVER 5Y', ['CDX HY 5Y'], 'ITRX XOVER 5Y', ['CDX HY 5Y'],],\n",
    "            \n",
    "        ]\n",
    "        l1, t1 = x_model(3, models_list, diff_list, calc)\n",
    "        l2 = pd.concat([l2,l1],axis=1)\n",
    "        times_list += t1  \n",
    "        \n",
    "        models_list = [ \n",
    "            ['EMB', ['EEM'], 'EMB', ['EEM'],],\n",
    "            ['CDX EM 5Y', ['CDX IG 5Y'], 'CDX EM 5Y', ['CDX IG 5Y'],],\n",
    "            ['CDX EM 5Y', ['ITRX XOVER 5Y'], 'CDX EM 5Y', ['ITRX XOVER 5Y'],],\n",
    "            ['CDX EM 5Y', ['EEM'], 'CDX EM 5Y', ['EEM'],],\n",
    "        ]\n",
    "        l1, t1 = x_model(3, models_list, diff_list, calc)\n",
    "        l2 = pd.concat([l2,l1],axis=1)\n",
    "        times_list += t1\n",
    "        all_zscore_values += [[item for item in l2.columns]]\n",
    "    \n",
    "    # ########################################################################################## Combining them\n",
    "    \n",
    "    df = pd.DataFrame({'PX_Zscore 1/2/3w':all_zscore_values[0]})\n",
    "    df['Rtn_Zscore 6/9/12w'] = [item.split(\": \")[1] for item in all_zscore_values[1]]\n",
    "    \n",
    "    df['Pair'] = df['PX_Zscore 1/2/3w'].apply(lambda x: x.split(\" ZScore: \")[0])\n",
    "    df['PX_Zscore 1/2/3w'] = df['PX_Zscore 1/2/3w'].apply(lambda x: x.split(\" ZScore: \")[1])\n",
    "    df['Pair'] = df['Pair'].str.replace(\"(\",\" (\")\n",
    "    df['Long Risk'] = df['Pair'].apply(lambda x: x.split(\" vs. \")[0])\n",
    "    df['Short Risk'] = df['Pair'].apply(lambda x: x.split(\" vs. \")[1])\n",
    "    df = df[['Long Risk','Short Risk','PX_Zscore 1/2/3w','Rtn_Zscore 6/9/12w']]\n",
    "    df['Long Ref.'] = df['Long Risk'].apply(lambda x: x.split(\" (\")[1].replace(\")\",\"\"))\n",
    "    df['Long Risk'] = df['Long Risk'].apply(lambda x: x.split(\" (\")[0].replace(\"CDX \",\"\").\\\n",
    "                                            replace(\"ITRX \",\"\").replace(\" 5Y\",\"\").replace(\"SPX\",\"ESA Implied SPY\"))\n",
    "    df['Short Ref.'] = df['Short Risk'].apply(lambda x: x.split(\" (\")[1].replace(\")\",\"\"))\n",
    "    df['Short Ref.'] = df['Short Ref.'].apply(lambda x: f\"['{x.split(\" & \")[0]}', '{x.split(\" & \")[1]}']\" if \"&\" in x else x)\n",
    "    df['Short Risk'] = df['Short Risk'].apply(lambda x: x.split(\" (\")[0])\n",
    "    df['Short Risk'] = df['Short Risk'].apply(lambda x: x.replace(\"ITRX \",\"\").\\\n",
    "                                              replace(\" 5Y\",\"\").replace(\"SPX\",\"ESA Implied SPY\").replace(\"CDX \",\"\"))\n",
    "    df['Valuation'] = df.apply(lambda row: f\"{row['Long Risk']} {'rich' if eval(row['PX_Zscore 1/2/3w'])\\\n",
    "    >0 else 'cheap'} to {row['Short Risk']}\",axis=1)\n",
    "   \n",
    "    df = df[['Long Risk','Long Ref.','Short Risk','Short Ref.','PX_Zscore 1/2/3w','Rtn_Zscore 6/9/12w','Valuation']].copy()\n",
    "    df['Last Update'] = [item.strftime(\"%d-%b %I:%M %p\") for item in times_list]\n",
    "    df = df.rename(columns={\"Long Ref.\":\"Ref\",\"Short Ref.\":\"Ref.\"})\n",
    "    \n",
    "    formatted_time = bbg_time.strftime(\"%I:%M %p\")\n",
    "    df.columns = pd.MultiIndex.from_tuples([(formatted_time, col) for col in df.columns])\n",
    "    \n",
    "    styled_df = (\n",
    "        df.style\n",
    "        .apply(color_negative_red_positive_green_basis, subset=[df.columns[4]], axis=0)\n",
    "        .apply(color_negative_red_positive_green_basis, subset=[df.columns[5]], axis=0)\n",
    "        .applymap(bold_zscore, subset=pd.IndexSlice[:, df.columns[4]])\n",
    "        .apply(add_black_line, axis=1)\n",
    "        .hide(axis=\"index\")\n",
    "    )\n",
    "    \n",
    "    update_display(styled_df,display_id=\"DFA\")\n",
    "    # bbg_datafile.to_parquet(\"bbg1.parquet\")\n",
    "    # all_intraday_er_series.to_parquet(\"er1.parquet\")\n",
    "    # if datetime.now().time()==pd.to_datetime(\"09:33\").time():\n",
    "    #     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
