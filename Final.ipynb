{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e670e7-6fdc-4f86-888b-69ffbe02ca11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pytz\n",
    "import time\n",
    "import os\n",
    "from xbbg import blp\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact, Dropdown, HBox, VBox, Button, Output, Text, widgets\n",
    "import sympy as sp\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output, update_display\n",
    "from IPython import get_ipython\n",
    "# import backtrader.plot as btplot\n",
    "import matplotlib.dates as mdates\n",
    "from pydataquery import DataQuery\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import warnings\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import yfinance as yf\n",
    "import uuid\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##### Style df\n",
    "def bold_zscore(val):\n",
    "    return 'font-weight: bold' if val else ''\n",
    "\n",
    "def add_black_line(row):\n",
    "    return ['border-bottom: 3px solid black' if row.name in [2, 7, 13, 15, 17, 21] else '' for _ in row]\n",
    "\n",
    "def color_negative_red_positive_green_basis(col: pd.Series):\n",
    "    if col.empty:\n",
    "        return ['' for _ in col]\n",
    "\n",
    "    def safe_float(x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except (ValueError, TypeError):\n",
    "            return None\n",
    "\n",
    "    float_col = col.apply(safe_float)\n",
    "    min_val = float_col.min(skipna=True)\n",
    "    max_val = float_col.max(skipna=True)\n",
    "\n",
    "    def value_to_color(val):\n",
    "        if val is None:\n",
    "            return ''\n",
    "        if val < 0 and min_val < 0:\n",
    "            frac = val / min_val\n",
    "            frac = max(min(frac, 1), 0)\n",
    "            r = int(255 - (255 - 87) * frac)\n",
    "            g = int(255 - (255 - 187) * frac)\n",
    "            b = int(255 - (255 - 138) * frac)\n",
    "            return f'background-color: rgba({r},{g},{b},0.75)'\n",
    "        elif val > 0 and max_val > 0:\n",
    "            frac = val / max_val\n",
    "            frac = max(min(frac, 1), 0)\n",
    "            r = int(255 - (255 - 230) * frac)\n",
    "            g = int(255 - (255 - 135) * frac)\n",
    "            b = int(255 - (255 - 115) * frac)\n",
    "            return f'background-color: rgba({r},{g},{b},0.75)'\n",
    "        return ''\n",
    "\n",
    "    return [value_to_color(v) for v in float_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fccbf4-98ba-424f-90ae-ca08b44f4161",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #ER Code\n",
    "# ####################################################\n",
    "\n",
    "# all_start_date = str((datetime.now()-timedelta(days=6*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#         \"LQD Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_USDLIG_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"HYG Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_USDHY_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"IEAC Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_EURIG_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"IHYG Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_EURHY_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"Fed Fund\": \"FF\",\n",
    "#         \"ER CDX IG 5Y\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX IG 10Y\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX HY 5Y\": \"DB(CDS,TRAC-X,NAHY100UNF05ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX HY 10Y\": \"DB(CDS,TRAC-X,NAHY100UNF10ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX EM 5Y\": \"DB(NEO-UK,credit/cds/index/cdxEM-onrun/5y/JPM_RETURN)\",\n",
    "#         \"ER ITRX MAIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX MAIN 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX XOVER 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX SNRFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX SUBFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# dq = df.copy()\n",
    "\n",
    "# # dq['Fed Fund'] = dq['Fed Fund'].ffill()\n",
    "\n",
    "# end_date = dq.index[-1]\n",
    "# ####################################### BBG Data Acquisition\n",
    "\n",
    "# securities = ['HYG US Equity','EMB US Equity','LQD US Equity','VCIT US Equity',\n",
    "#               'IEAC LN Equity','IHYG LN EQUITY', 'BKLN US EQUITY', 'IBCN GR EQUITY',\n",
    "#               'IEI US Equity','IEF US Equity']\n",
    "\n",
    "# fields1 = ['YAS_MOD_DUR']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields1)\n",
    "# df.columns = [item.split(' ')[0] + ' DUR' for item in securities]\n",
    "# df1 = df.copy()\n",
    "\n",
    "# #################################### Fixing Bad Data Point in YAS of IEI\n",
    "# rolling_avg = df1['IEI DUR'].replace(0, np.nan).rolling(window=30, min_periods=1).mean()\n",
    "# df1['IEI DUR'] = df1.apply(\n",
    "#     lambda row: rolling_avg[row.name] if row['IEI DUR'] == 0.0 else row['IEI DUR'], axis=1\n",
    "# )\n",
    "# #################################### Fixing Bad Data Point in YAS of IEI\n",
    "\n",
    "# securities = ['LT03TRUU INDEX','LT09TRUU INDEX','QW3I INDEX', 'LT03MD INDEX','LT09MD INDEX']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields)\n",
    "# df.columns = ['TR ' + item.split(' ')[0] for item in securities[:3]] + [item.split(' ')[0] + ' DUR' for item in securities[:2]]\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['HYG US Equity','EMB US Equity','LQD US Equity','VCIT US Equity',\n",
    "#               'IEI US Equity','IEF US Equity', 'RSP US EQUITY', #'SPX INDEX',  'RTY INDEX',\n",
    "#               'IBCN GR EQUITY',\n",
    "#               'IEAC LN Equity','IHYG LN EQUITY', 'BKLN US EQUITY',\n",
    "#               'GSCBHYEQ Index', 'GSCBIGEQ Index', 'SPY US EQUITY', 'EEM US EQUITY', 'IWM US EQUITY', 'IJH US EQUITY',\n",
    "#              ]\n",
    "\n",
    "# fields = ['TOT_RETURN_INDEX_GROSS_DVDS']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields)\n",
    "# df.columns = ['TR ' + item.split(' ')[0] for item in securities] \n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['QW3I INDEX']\n",
    "# fields = ['MODIFIED_DURATION']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields)\n",
    "# df.columns = [item.split(' ')[0] + ' DUR' for item in securities]\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# # securities = ['SPXFP INDEX', 'RTYFPE INDEX','SX5EFSER Index']  ############## I want to calculate funding rate for spx, rty and sx5e separately\n",
    "# # fields = ['PX_LAST']\n",
    "# # df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields)\n",
    "# # df.columns = ['ER SPX','ER RTY','ER SX5E']\n",
    "# # df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['EURR002W Index']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, flds = fields)\n",
    "# df.columns = ['ECB Rate']\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# bbg = df1.copy()\n",
    "# dq.index = pd.to_datetime(dq.index)\n",
    "# dq.index = dq.index.date\n",
    "# bbg.index = pd.to_datetime(bbg.index)\n",
    "# bbg.index = bbg.index.date\n",
    "\n",
    "# data = pd.concat([dq,bbg],axis=1)\n",
    "# data = data.sort_index()\n",
    "\n",
    "# df_funding = data[[col for col in data.columns if ('Funding Sprd' in col)]+['Fed Fund']+['ECB Rate']]\n",
    "\n",
    "# if np.isnan(df_funding.loc[df_funding.index[-1],'Fed Fund']):\n",
    "#     df_funding.loc[df_funding.index[-1],'Fed Fund'] = df_funding.loc[df_funding.index[-2],'Fed Fund']\n",
    "\n",
    "# # df_funding['Fed Fund'] = df_funding['Fed Fund'].ffill()\n",
    "\n",
    "# for col in df_funding:\n",
    "#     if col.endswith('Sprd'):\n",
    "#         if col.split(' ')[0] in ['HYG','LQD']:\n",
    "#             df_funding[f'Net Long {col.replace(\" Sprd\",\"\")}'] = (df_funding['Fed Fund'] + df_funding[f'{col}']/100) + 0.25/100\n",
    "#             df_funding[f'Net Short {col.replace(\" Sprd\",\"\")}'] = (df_funding['Fed Fund'] + df_funding[f'{col}']/100) - 0.25/100\n",
    "#         if col.split(' ')[0] in ['IHYG','IEAC']:\n",
    "#             df_funding[f'Net Long {col.replace(\" Sprd\",\"\")}'] = (df_funding['ECB Rate'] + df_funding[f'{col}']/100) + 0.25/100\n",
    "#             df_funding[f'Net Short {col.replace(\" Sprd\",\"\")}'] = (df_funding['ECB Rate'] + df_funding[f'{col}']/100) - 0.25/100\n",
    "\n",
    "# df_funding['Net Long VCIT Funding'] = df_funding['Net Long LQD Funding']\n",
    "# df_funding['Net Short VCIT Funding'] = df_funding['Net Short LQD Funding']\n",
    "\n",
    "# for item in ['EMB','EEM']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['Fed Fund'] + 0.5\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['Fed Fund'] - 0.5\n",
    "\n",
    "# for item in ['IEI', 'IEF', 'RSP', 'BKLN', 'GSCBHYEQ', 'GSCBIGEQ', 'SPX', 'RTY', 'SPY', 'IWM', 'IJH']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['Fed Fund'] + 0.15\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['Fed Fund'] - 0.15\n",
    "\n",
    "# for item in ['IBCN','SX5E']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['ECB Rate'] + 0.15\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['ECB Rate'] - 0.15\n",
    "\n",
    "# df_funding = df_funding[[col for col in df_funding.columns if col.startswith(\"Net\")]]\n",
    "# df_funding.index = pd.to_datetime(df_funding.index)\n",
    "# df_funding = df_funding.resample('D').last().ffill()\n",
    "\n",
    "# original_er_data = data[[col for col in data.columns if col.startswith(\"ER \")]]\n",
    "# tr_data = data[[col for col in data.columns if col.startswith(\"TR \")]]\n",
    "# ust = tr_data[['TR LT09TRUU']] # for using corr later\n",
    "# tr_data = tr_data.iloc[:,:-3] #dropping LT03/09 and QW3I\n",
    "\n",
    "# tr_data.index = pd.to_datetime(tr_data.index).date\n",
    "# df_funding.index = pd.to_datetime(df_funding.index).date\n",
    "\n",
    "# er_tr_data = pd.concat([tr_data,df_funding],axis=1)\n",
    "# er_tr_data = er_tr_data.sort_index()\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# etfs = [col for col in er_tr_data.columns if col.startswith(\"TR \")]\n",
    "\n",
    "# for item in etfs:\n",
    "#     check = er_tr_data[item].dropna()\n",
    "#     check = check.diff()/check.shift()\n",
    "#     check = check.reindex(er_tr_data.index)\n",
    "#     er_tr_data[item] = check\n",
    "    \n",
    "# er_tr_data['Date'] = pd.to_datetime(er_tr_data.index)\n",
    "# er_tr_data['Days'] = (er_tr_data['Date'] - er_tr_data['Date'].shift()).dt.days\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# ############################################################### Funding Sprds\n",
    "# funding = er_tr_data[[col for col in er_tr_data.columns if 'Funding' in col]].copy()\n",
    "# x = er_tr_data[[col for col in er_tr_data.columns if 'Funding' in col]].copy()\n",
    "# x = x.interpolate()\n",
    "# x.to_excel(\"Funding Rates.xlsx\")\n",
    "\n",
    "# y = x.copy()\n",
    "# y = round(y,2)\n",
    "# y.to_excel(\"Funding Rates 2.xlsx\")\n",
    "\n",
    "# ###############################################################\n",
    "# for item in etfs:\n",
    "#     name = item.split(' ')[1]\n",
    "#     er_tr_data[f'ER {name}'] = er_tr_data[item] - \\\n",
    "#                 (1/100)*(er_tr_data['Days']/360)*(0.5*(er_tr_data[f'Net Long {name} Funding'] + er_tr_data[f'Net Short {name} Funding']))\n",
    "\n",
    "\n",
    "# er_tr_data = er_tr_data[[col for col in er_tr_data.columns if col.startswith(\"ER \")]]\n",
    "# er_tr_data = (1+er_tr_data).cumprod()\n",
    "\n",
    "# tr_data.index = pd.to_datetime(tr_data.index).date\n",
    "# df_funding.index = pd.to_datetime(df_funding.index).date\n",
    "\n",
    "# er_tr_data = pd.concat([tr_data,df_funding],axis=1)\n",
    "# er_tr_data = er_tr_data.sort_index()\n",
    "\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# etfs = [col for col in er_tr_data.columns if col.startswith(\"TR \")]\n",
    "\n",
    "# for item in etfs:\n",
    "#     check = er_tr_data[item].dropna()\n",
    "#     check = check.diff()/check.shift()\n",
    "#     check = check.reindex(er_tr_data.index)\n",
    "#     er_tr_data[item] = check\n",
    "\n",
    "# er_tr_data['Date'] = pd.to_datetime(er_tr_data.index)\n",
    "# er_tr_data['Days'] = (er_tr_data['Date'] - er_tr_data['Date'].shift()).dt.days\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# for item in etfs:\n",
    "#     name = item.split(' ')[1]\n",
    "#     er_tr_data[f'ER {name}'] = er_tr_data[item] - \\\n",
    "#                 (1/100)*(er_tr_data['Days']/360)*(0.5*(er_tr_data[f'Net Long {name} Funding'] + er_tr_data[f'Net Short {name} Funding']))\n",
    "\n",
    "# er_tr_data = er_tr_data[[col for col in er_tr_data.columns if col.startswith(\"ER \")]]\n",
    "# er_tr_data = (1+er_tr_data).cumprod()\n",
    "\n",
    "# er_data = pd.concat([original_er_data,er_tr_data],axis=1)\n",
    "# # er_data = er_data.dropna()\n",
    "# # er_data.columns = er_data.columns.str.replace(\"ER SPX\",\"ER ESA\").str.replace(\"ER RTY\",\"ER RTYA\").str.replace(\"ER SX5E\",\"ER VGA\")\n",
    "# er_data.columns = er_data.columns.str.replace(\"ER GSCBHYEQ\",\"ER HY Eqty\").str.replace(\"ER GSCBIGEQ\",\"ER IG Eqty\")\n",
    "# er_data = er_data.sort_index()\n",
    "\n",
    "# securities = ['SPXFP INDEX', 'RTYFPE INDEX','SX5EFSER Index']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = er_data.index[0], flds = fields)\n",
    "# df.columns = ['ER SPX','ER RTY','ER SX5E']\n",
    "# er_data = pd.concat([er_data,df], axis=1)\n",
    "# er_data = er_data.sort_index()\n",
    "\n",
    "# er_data.to_csv(\"All ER.csv\")\n",
    "\n",
    "# ##############################################################  Updating Durations\n",
    "\n",
    "# all_start_date = str((datetime.now()-timedelta(days=6*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#         \"CDX IG 5Y Dur\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_DUR)\",\n",
    "#         \"CDX IG 10Y Dur\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_DUR)\",\n",
    "#         \"ITRX XOVER 5Y Dur\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_DUR)\",\n",
    "#         \"ITRX MAIN 5Y Dur\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_DUR)\",\n",
    "#         \"ITRX MAIN 10Y Dur\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_DUR)\",\n",
    "#         \"ITRX SUBFIN 5Y Dur\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_DUR)\",\n",
    "#         \"ITRX SNRFIN 5Y Dur\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_DUR)\",\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# df.index = pd.to_datetime(df.index)\n",
    "# df.loc[pd.to_datetime(datetime.now().date())] = [item - ((datetime.now() - df.index[-1]).days)/365 for item in list(df.iloc[-1])]\n",
    "# df = df.interpolate()\n",
    "# all_dq_dur = df.copy()\n",
    "# all_dq_dur.to_excel(\"All DQ Duration.xlsx\")\n",
    "\n",
    "# ############################################################################## Updating Ref levels\n",
    "\n",
    "# all_start_date = str((datetime.now()-timedelta(days=6*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#     \"CDX IG 5Y\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX IG 10Y\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX HY 5Y\": \"DB(CDS,TRAC-X,NAHY100UNF05ONRUN,JPM_CLEAN_MID)\",\n",
    "#     \"ITRX MAIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX MAIN 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX SNRFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX SUBFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX XOVER 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX EM 5Y\": \"DB(NEO-UK,credit/cds/index/cdxEM-onrun/5y/JPM_CLEAN_MID)\",\n",
    "\n",
    "#     \"CDX IG 5Y DUR\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_DUR)\",\n",
    "#     \"CDX IG 10Y DUR\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_DUR)\",\n",
    "#     \"ITRX MAIN 5Y DUR\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX MAIN 10Y DUR\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_DUR)\",\n",
    "#     \"ITRX SNRFIN 5Y DUR\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX SUBFIN 5Y DUR\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX XOVER 5Y DUR\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_DUR)\",\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "# df.index = pd.to_datetime(df.index)\n",
    "# df.to_excel(\"Ref Levels.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e454257-447a-4edb-9780-c2be8d0388a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "roll_series = {\n",
    "    \"CDX IG 5Y\": {\n",
    "        \"S44\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S45\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S46\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S47\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "    },\n",
    "    \"CDX HY 5Y\": {\n",
    "        \"S44\": [\"2025-07-04\", \"2026-01-04\"],\n",
    "        \"S45\": [\"2026-01-05\", \"2026-07-03\"],\n",
    "        \"S46\": [\"2026-07-04\", \"2027-01-03\"],\n",
    "        \"S47\": [\"2027-01-04\", \"2027-07-05\"]\n",
    "    },\n",
    "    \"CDX EM 5Y\": {\n",
    "        \"S43\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S44\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S45\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S46\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "    },\n",
    "    \"ITRX MAIN 5Y\": {\n",
    "        \"S43\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S44\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S45\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S46\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "    },\n",
    "    \"ITRX XOVER 5Y\": {\n",
    "        \"S43\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S44\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S45\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S46\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "    },\n",
    "    \"ITRX SNRFIN 5Y\": {\n",
    "        \"S43\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S44\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S45\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S46\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "    },\n",
    "    \"ITRX SUBFIN 5Y\": {\n",
    "        \"S43\": [\"2025-06-27\", \"2025-12-28\"],\n",
    "        \"S44\": [\"2025-12-29\", \"2026-06-26\"],\n",
    "        \"S45\": [\"2026-06-27\", \"2026-12-27\"],\n",
    "        \"S46\": [\"2026-12-28\", \"2027-06-28\"]\n",
    "}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a8e4bb-f946-47e8-93f3-a1d0935fd309",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "today = datetime.now()\n",
    "current_series = {}\n",
    "for key, val in roll_series.items():\n",
    "    for series, dates_list in val.items():\n",
    "        if pd.to_datetime(dates_list[0])<= today and today<=pd.to_datetime(dates_list[1]):\n",
    "            current_series[key] = series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a53296c-7cfc-4705-bd3c-dd2e3ae925b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_dq_dur = pd.read_excel(\"All DQ Duration.xlsx\")\n",
    "all_dq_dur['Date'] = pd.to_datetime(all_dq_dur['Date'])\n",
    "all_dq_dur = all_dq_dur.set_index('Date')\n",
    "\n",
    "dict_map = {\n",
    "# product type, start time, end time, carry (%), trades on sprd, slippage (bps or $),\n",
    "# fixed commission, notional (if selected as Y), BBG ticker, check live status using which ticker\n",
    "    'CDX IG 5Y': ['CDX', '07:30:00', '20:00:00', 1, 'Yes', 0.15, 500, 30*10**6, f\"CDX IG CDSI {current_series[\"CDX IG 5Y\"]} 5Y CORP\", \"CDX IG CDSI GEN 5Y CORP\"],\n",
    "    'CDX IG 10Y': ['CDX', '07:30:00', '20:00:00', 1, 'Yes', 0.3, 500, 30*10**6, f\"CDX IG CDSI {current_series[\"CDX IG 5Y\"]} 10Y CORP\", \"CDX IG CDSI GEN 5Y CORP\"],\n",
    "    'CDX HY 5Y': ['CDX', '07:30:00', '20:00:00', 5, 'No', 0.02, 500, 6*10**6, f\"CDX HY CDSI {current_series[\"CDX HY 5Y\"]} 5Y CORP\", \"CDX IG CDSI GEN 5Y CORP\"],\n",
    "    'SPX': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"SPX INDEX\", \"ESA INDEX\"],\n",
    "    'SPY': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"SPY US EQUITY\", \"ESA INDEX\"],\n",
    "    'IWM': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"IWM US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'RSP': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"RSP US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'RTY': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"RTY INDEX\", \"RSP US EQUITY\"],\n",
    "    'IG Eqty': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"GSCBIGEQ Index\", \"RSP US EQUITY\"],\n",
    "    'HY Eqty': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"GSCBHYEQ Index\", \"RSP US EQUITY\"],\n",
    "    'ITRX MAIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 500, 30*10**6, f\"ITRX EUR CDSI {current_series[\"ITRX MAIN 5Y\"]} 5Y CORP\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX MAIN 10Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.3, 500, 30*10**6, f\"ITRX EUR CDSI {current_series[\"ITRX MAIN 5Y\"]} 10Y CORP\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX SNRFIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 500, 30*10**6, f\"SNRFIN CDSI {current_series[\"ITRX SNRFIN 5Y\"]} 5Y Corp\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX SUBFIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 500, 30*10**6, f\"SUBFIN CDSI {current_series[\"ITRX SUBFIN 5Y\"]} 5Y Corp\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX XOVER 5Y': ['CDX', '03:30:00', '11:59:00', 5, 'Yes', 0.15, 500, 6*10**6, f\"ITRX XOVER CDSI {current_series[\"ITRX XOVER 5Y\"]} 5Y CORP\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX XOVER 10Y': ['CDX', '03:30:00', '11:59:00', 5, 'Yes', 0.3, 500, 6*10**6, f\"ITRX XOVER CDSI {current_series[\"ITRX XOVER 5Y\"]} 10Y CORP\", \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    # 'VIX': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"VIX INDEX\", \"RSP US EQUITY\"],\n",
    "    # 'V2X': ['Eq', '03:30:00', '11:59:00', 0, 'No', 0.01, 0, 10**6, \"V2X INDEX\", \"SX5E INDEX\"],\n",
    "    'SX5E': ['Eq', '03:30:00', '11:59:00', 0, 'No', 0.01, 0, 10**6, \"SX5E INDEX\", \"SX5E INDEX\"],\n",
    "    'CDX EM 5Y': ['CDX', '07:30:00', '20:00:00', 1, 'No', 0.02, 500, 6*10**6, f\"CDX EM CDSI {current_series[\"CDX EM 5Y\"]} 5Y CORP\", \"CDX IG CDSI GEN 5Y CORP\"],\n",
    "    'HYG': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"HYG US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'EMB': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"EMB US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'VCIT': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"VCIT US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'LQD': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"LQD US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'IEI': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"IEI US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'IEF': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"IEF US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'EEM': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"EEM US EQUITY\", \"RSP US EQUITY\"],\n",
    "    'IJH': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, 10**6, \"IJH US EQUITY\", \"RSP US EQUITY\"],\n",
    "}\n",
    "\n",
    "l1 = list(dict_map.keys())\n",
    "l2 = [item[8] for item in list(dict_map.values())]\n",
    "reverse_dict = dict(zip(l2,l1))\n",
    "reverse_dict[\"ESA INDEX\"] = \"ESA\"\n",
    "\n",
    "live_dict = dict(zip([item[8] for item in dict_map.values()], [item[9] for item in dict_map.values()]))\n",
    "live_dict[\"ESA INDEX\"] = \"ESA INDEX\"\n",
    "\n",
    "last_checked = None\n",
    "current_date_esa_close = datetime.now()\n",
    "first_current_date_esa_close = True\n",
    "first_run = True\n",
    "\n",
    "df = pd.read_excel(\"Data for Credit-Eqty Dashboard v4.xlsx\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date')\n",
    "df = df.sort_index()\n",
    "bbg_datafile = df.copy()\n",
    "original_last_update = df.dropna().index[-1] #- timedelta(days=13*7)\n",
    "all_bbg_tickers = [dict_map[item][8] for item in df.columns]\n",
    "new_data = pd.DataFrame()\n",
    "\n",
    "for bbg_tickers in all_bbg_tickers:\n",
    "    if ((bbg_tickers[0].split(\" \")[0] == \"CDX\") or (bbg_tickers[0].split(\" \")[0] == \"ITRX\")):\n",
    "        last_update = original_last_update - timedelta(days=13*7)\n",
    "    else:\n",
    "        last_update = original_last_update\n",
    "    bbg_date = pd.to_datetime(last_update.date())\n",
    "    data = None\n",
    "    while True:\n",
    "        try:\n",
    "            f = blp.bdib(ticker = bbg_tickers, dt = bbg_date, interval = 1, ref='IndexYieldCurve')      \n",
    "        except:\n",
    "            if bbg_date > pd.to_datetime(datetime.now().date()):\n",
    "                break\n",
    "        data = pd.concat([data,f])\n",
    "        bbg_date += timedelta(days=1)    \n",
    "    try:\n",
    "        data = data.iloc[:,[3]].copy()\n",
    "        data.columns = [bbg_tickers]\n",
    "    except:\n",
    "        continue\n",
    "    new_data = pd.concat([new_data, data],axis=1)\n",
    "\n",
    "new_data.index = new_data.index.tz_convert('America/New_York')\n",
    "new_data.index = new_data.index.tz_localize(None)\n",
    "\n",
    "live_list = ['CDX IG CDSI GEN 5Y CORP','ITRX EUR CDSI GEN 5Y CORP', 'RSP US EQUITY','SX5E INDEX','ESA INDEX']\n",
    "# live_list = [f\"CDX IG CDSI {current_series[\"CDX IG 5Y\"]} 5Y CORP\", f\"ITRX EUR CDSI {current_series[\"ITRX MAIN 5Y\"]} 5Y CORP\",\n",
    "#              'RSP US EQUITY','SX5E INDEX','ESA INDEX']\n",
    "\n",
    "mask = blp.bdh(tickers = live_list, flds='PX_LAST', start_date = df.index[0]-timedelta(days=5))\n",
    "mask.columns = live_list\n",
    "mask.index = pd.to_datetime(mask.index).date\n",
    "\n",
    "new_data = new_data.ffill()\n",
    "new_data.index = pd.to_datetime(new_data.index)\n",
    "new_data.columns = [reverse_dict[item] for item in new_data.columns]\n",
    "\n",
    "\n",
    "bbg_datafile = bbg_datafile[bbg_datafile.index<new_data.index[0]].copy()\n",
    "bbg_datafile = pd.concat([bbg_datafile, new_data])\n",
    "bbg_datafile = bbg_datafile.sort_index()\n",
    "bbg_datafile.index.name = 'Date'\n",
    "bbg_datafile = bbg_datafile.ffill().copy()\n",
    "bbg_datafile = bbg_datafile[~bbg_datafile.index.duplicated(keep='last')]\n",
    "\n",
    "bbg_datafile['Date'] = pd.to_datetime(bbg_datafile.index.date)\n",
    "bbg_datafile['Time'] = bbg_datafile.index.time\n",
    "filtered_new_data = None\n",
    "\n",
    "for col in bbg_datafile.drop(['Date','Time'],axis=1).columns:\n",
    "    test = bbg_datafile[[col,'Date','Time']]\n",
    "    cond = (test['Date'].isin(mask[dict_map[col][9]].dropna().index)) & (test['Time']<=pd.\\\n",
    "            to_datetime(dict_map[col][2]).time()) & (test['Time']>=pd.to_datetime(dict_map[col][1]).time())\n",
    "    test = test[cond][[col]]\n",
    "    filtered_new_data = pd.concat([filtered_new_data, test],axis=1)\n",
    "\n",
    "bbg_datafile = filtered_new_data.copy()\n",
    "\n",
    "bbg_datafile = bbg_datafile.dropna(how='all')\n",
    "bbg_datafile.to_excel(\"Data for Credit-Eqty Dashboard v4.xlsx\")    \n",
    "master_bbg_datafile = bbg_datafile.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80200623-6dd6-4a06-a4fd-61569a429d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c52886c5-8fc6-4571-be61-942a429d6a1c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Ref Levels.xlsx\", index_col=0, parse_dates=True)\n",
    "\n",
    "ref = df[[col for col in df.columns if not col.endswith(\"DUR\")]]\n",
    "\n",
    "dur = df[[col for col in df.columns if col.endswith(\"DUR\")]]\n",
    "dur.loc[datetime.now()] = [np.nan] * len(dur.columns)\n",
    "dur = dur.resample(\"D\").last().ffill().copy()\n",
    "dur = dur.shift().resample(\"1min\").last().ffill().copy()  ############ yesterday's duration we take .. we have shifted it here\n",
    "dur.columns = [item.rsplit(\" \",1)[0] + '_dq_dur' for item in dur.columns]\n",
    "\n",
    "#########################################################################################\n",
    "bbg_tickers = [dict_map[item][8] for item in dict_map.keys()]\n",
    "# reverse_dict = dict(zip(bbg_tickers, list(dict_map.keys())))\n",
    "bbg_data = blp.bdh(tickers = bbg_tickers, flds='px_last', start_date='2017-01-01')\n",
    "bbg_data.columns = bbg_tickers\n",
    "bbg_data.index = pd.to_datetime(bbg_data.index)\n",
    "bbg_data.columns = [reverse_dict[item] for item in bbg_data.columns]\n",
    "\n",
    "for col in ref.columns:\n",
    "    bbg_data[col] = ref[col]\n",
    "\n",
    "bbg_data['ESA'] = bbg_data['SPY']\n",
    "\n",
    "bbg_data1 = bbg_data.resample(\"1min\").last().ffill().copy()\n",
    "bbg_data1.columns = [item +'_bbg_px' for item in bbg_data1.columns]\n",
    "\n",
    "bbg_data2 = bbg_data.shift().resample(\"1min\").last().ffill().copy()\n",
    "bbg_data2.columns = [item +'_bbg_px_2' for item in bbg_data2.columns]\n",
    "\n",
    "################################################## Creating SPY Imputed for recent day in BBG_DATFILE\n",
    "\n",
    "bbg_datafile[\"ESA\"] = bbg_datafile[\"SPY\"]\n",
    "\n",
    "last_close = None\n",
    "for tick in ['ESA INDEX','SPY US EQUITY']:\n",
    "    f = blp.bdib(ticker=tick, flds='PX_LAST', dt=str(list(sorted(set(bbg_datafile[['SPY']].dropna().index.date)))[-2]), ref='IndexUS')\n",
    "    f.index = f.index.tz_convert('America/New_York').tz_localize(None)\n",
    "    f = f.iloc[:,[3]]\n",
    "    f.columns = [tick]\n",
    "    last_close = pd.concat([last_close,f],axis=1)\n",
    "\n",
    "esa_val = last_close['ESA INDEX'].ffill().iloc[-1]\n",
    "spx_val = last_close['SPY US EQUITY'].iloc[-1]\n",
    "\n",
    "tick = \"ESA INDEX\"\n",
    "start_date = list(sorted(set(bbg_datafile[['SPY']].dropna().index.date)))[-1]\n",
    "all_f = None\n",
    "for i in range(4):\n",
    "    try:\n",
    "        f = blp.bdib(ticker=tick, flds='PX_LAST', dt=str(start_date+timedelta(days=i)), ref='IndexYieldCurve')\n",
    "        f.index = f.index.tz_convert('America/New_York').tz_localize(None)\n",
    "        f = f.iloc[:,[3]]\n",
    "        f.columns = [tick]\n",
    "        all_f = pd.concat([f, all_f]).sort_index().copy()\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "f = all_f.copy()\n",
    "f = f[f.index.date == pd.to_datetime(str(list(sorted(set(bbg_datafile[['SPY']].dropna().index.date)))[-1])).date()]\n",
    "f['SPY Imputed'] = round((f/esa_val) * spx_val,2)\n",
    "f = f[['SPY Imputed']].copy()\n",
    "f.columns = ['ESA']\n",
    "\n",
    "recent_spy = bbg_datafile[bbg_datafile.index.date<list(sorted(set(bbg_datafile[['SPY']].dropna().index.date)))[-1]][['ESA']]\n",
    "new_spy = pd.concat([recent_spy, f]).sort_index().copy()\n",
    "bbg_datafile = pd.concat([bbg_datafile.drop(\"ESA\",axis=1), new_spy], axis=1).sort_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92279555-e4e1-45c7-84dd-b6a4ae86ac3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDX IG 5Y</th>\n",
       "      <th>CDX IG 10Y</th>\n",
       "      <th>LQD</th>\n",
       "      <th>CDX HY 5Y</th>\n",
       "      <th>CDX EM 5Y</th>\n",
       "      <th>VCIT</th>\n",
       "      <th>HYG</th>\n",
       "      <th>EMB</th>\n",
       "      <th>IEI</th>\n",
       "      <th>IEF</th>\n",
       "      <th>...</th>\n",
       "      <th>RSP</th>\n",
       "      <th>RTY</th>\n",
       "      <th>ITRX MAIN 5Y</th>\n",
       "      <th>ITRX XOVER 5Y</th>\n",
       "      <th>SX5E</th>\n",
       "      <th>SPY</th>\n",
       "      <th>EEM</th>\n",
       "      <th>IWM</th>\n",
       "      <th>IJH</th>\n",
       "      <th>ESA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-02 03:35:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3835.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02 03:45:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3833.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02 03:55:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3844.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02 04:05:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3844.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02 04:15:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3846.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-25 16:58:00</th>\n",
       "      <td>48.955</td>\n",
       "      <td>89.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.6184</td>\n",
       "      <td>98.392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>658.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-25 16:59:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>658.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-25 17:00:00</th>\n",
       "      <td>48.955</td>\n",
       "      <td>89.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.6184</td>\n",
       "      <td>98.392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-25 17:02:00</th>\n",
       "      <td>48.955</td>\n",
       "      <td>89.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.6184</td>\n",
       "      <td>98.392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-25 17:04:00</th>\n",
       "      <td>48.955</td>\n",
       "      <td>89.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.6184</td>\n",
       "      <td>98.392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114434 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     CDX IG 5Y  CDX IG 10Y  LQD  CDX HY 5Y  CDX EM 5Y  VCIT  \\\n",
       "2023-01-02 03:35:00        NaN         NaN  NaN        NaN        NaN   NaN   \n",
       "2023-01-02 03:45:00        NaN         NaN  NaN        NaN        NaN   NaN   \n",
       "2023-01-02 03:55:00        NaN         NaN  NaN        NaN        NaN   NaN   \n",
       "2023-01-02 04:05:00        NaN         NaN  NaN        NaN        NaN   NaN   \n",
       "2023-01-02 04:15:00        NaN         NaN  NaN        NaN        NaN   NaN   \n",
       "...                        ...         ...  ...        ...        ...   ...   \n",
       "2025-09-25 16:58:00     48.955       89.35  NaN   107.6184     98.392   NaN   \n",
       "2025-09-25 16:59:00        NaN         NaN  NaN        NaN        NaN   NaN   \n",
       "2025-09-25 17:00:00     48.955       89.35  NaN   107.6184     98.392   NaN   \n",
       "2025-09-25 17:02:00     48.955       89.35  NaN   107.6184     98.392   NaN   \n",
       "2025-09-25 17:04:00     48.955       89.35  NaN   107.6184     98.392   NaN   \n",
       "\n",
       "                     HYG  EMB  IEI  IEF  ...  RSP  RTY  ITRX MAIN 5Y  \\\n",
       "2023-01-02 03:35:00  NaN  NaN  NaN  NaN  ...  NaN  NaN           NaN   \n",
       "2023-01-02 03:45:00  NaN  NaN  NaN  NaN  ...  NaN  NaN           NaN   \n",
       "2023-01-02 03:55:00  NaN  NaN  NaN  NaN  ...  NaN  NaN           NaN   \n",
       "2023-01-02 04:05:00  NaN  NaN  NaN  NaN  ...  NaN  NaN           NaN   \n",
       "2023-01-02 04:15:00  NaN  NaN  NaN  NaN  ...  NaN  NaN           NaN   \n",
       "...                  ...  ...  ...  ...  ...  ...  ...           ...   \n",
       "2025-09-25 16:58:00  NaN  NaN  NaN  NaN  ...  NaN  NaN           NaN   \n",
       "2025-09-25 16:59:00  NaN  NaN  NaN  NaN  ...  NaN  NaN           NaN   \n",
       "2025-09-25 17:00:00  NaN  NaN  NaN  NaN  ...  NaN  NaN           NaN   \n",
       "2025-09-25 17:02:00  NaN  NaN  NaN  NaN  ...  NaN  NaN           NaN   \n",
       "2025-09-25 17:04:00  NaN  NaN  NaN  NaN  ...  NaN  NaN           NaN   \n",
       "\n",
       "                     ITRX XOVER 5Y     SX5E  SPY  EEM  IWM  IJH     ESA  \n",
       "2023-01-02 03:35:00            NaN  3835.79  NaN  NaN  NaN  NaN     NaN  \n",
       "2023-01-02 03:45:00            NaN  3833.98  NaN  NaN  NaN  NaN     NaN  \n",
       "2023-01-02 03:55:00            NaN  3844.12  NaN  NaN  NaN  NaN     NaN  \n",
       "2023-01-02 04:05:00            NaN  3844.49  NaN  NaN  NaN  NaN     NaN  \n",
       "2023-01-02 04:15:00            NaN  3846.76  NaN  NaN  NaN  NaN     NaN  \n",
       "...                            ...      ...  ...  ...  ...  ...     ...  \n",
       "2025-09-25 16:58:00            NaN      NaN  NaN  NaN  NaN  NaN  658.16  \n",
       "2025-09-25 16:59:00            NaN      NaN  NaN  NaN  NaN  NaN  658.06  \n",
       "2025-09-25 17:00:00            NaN      NaN  NaN  NaN  NaN  NaN     NaN  \n",
       "2025-09-25 17:02:00            NaN      NaN  NaN  NaN  NaN  NaN     NaN  \n",
       "2025-09-25 17:04:00            NaN      NaN  NaN  NaN  NaN  NaN     NaN  \n",
       "\n",
       "[114434 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "691bfc3a-471a-40f5-ae22-e9c4210f28d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = bbg_datafile.copy()\n",
    "er_data = pd.read_csv(\"All ER.csv\",index_col=0, parse_dates=True)\n",
    "\n",
    "er_data.loc[datetime.now().date()] = [np.nan] * len(er_data.columns)\n",
    "er_data.index = pd.to_datetime(er_data.index)\n",
    "er_data = er_data.resample(\"D\").last().ffill().copy()\n",
    "er_data.columns = [item.split(\"ER \",1)[1] for item in er_data.columns]\n",
    "er_data[['ESA']] = er_data[['SPY']]\n",
    "\n",
    "er = er_data.copy()\n",
    "er.columns = [item + '_dq_ER' for item in er.columns]\n",
    "er = er.resample(\"1min\").last().ffill().copy()\n",
    "\n",
    "er2 = er_data.shift().copy()\n",
    "er2.columns = [item + '_dq_ER_2' for item in er2.columns]\n",
    "er2 = er2.resample(\"1min\").last().ffill().copy()\n",
    "\n",
    "############################################################ Converting historical price series into historical er series\n",
    "\n",
    "intraday_tr_data = None\n",
    "\n",
    "for col in df.columns:    \n",
    "    first_run = False\n",
    "    if col == \"ESA\":\n",
    "        first_run = True\n",
    "    elif dict_map[col][0] == \"Eq\" or (dict_map[col][0] == \"CDX\" and dict_map[col][4] == 'No'):\n",
    "        first_run = True\n",
    "    \n",
    "    if first_run:\n",
    "        x = pd.concat([df[[col]], er[[f'{col}_dq_ER']], er2[[f'{col}_dq_ER_2']], bbg_data1[[f'{col}_bbg_px']],\\\n",
    "           bbg_data2[[f'{col}_bbg_px_2']],], axis=1).sort_index().dropna().copy()\n",
    "        \n",
    "        x['TR Change'] = (x[f'{col}_dq_ER'] / x[f'{col}_dq_ER_2'] - 1)\n",
    "        \n",
    "        if col in [\"CDX HY 5Y\", \"CDX HY 10Y\", \"CDX EM 5Y\"]:\n",
    "            x['d-o-d px pnl'] = (x[f'{col}_bbg_px'] - x[f'{col}_bbg_px_2']) * 10**(-2)\n",
    "            x['intraday px pnl'] = (x[col] - x[f'{col}_bbg_px_2']) * 10**(-2)\n",
    "        else:\n",
    "            x['d-o-d px pnl'] = (x[f'{col}_bbg_px']/ x[f'{col}_bbg_px_2'] - 1)\n",
    "            x['intraday px pnl'] = (x[col] / x[f'{col}_bbg_px_2'] - 1)\n",
    "            \n",
    "        x['Calculated TR Change'] = x['TR Change'] - x['d-o-d px pnl'] + x['intraday px pnl']\n",
    "        # x['Actual TR Series'] = (1 + x['Calculated TR Change']) * x[f'{col}_dq_ER_2']\n",
    "        # x = x[['Actual TR Series']].copy()\n",
    "        # x.columns = [col]\n",
    "    \n",
    "    \n",
    "    elif dict_map[col][4] == 'Yes':\n",
    "        x = pd.concat([df[[col]], er[[f'{col}_dq_ER']], er2[[f'{col}_dq_ER_2']], bbg_data1[[f'{col}_bbg_px']], bbg_data2[[f'{col}_bbg_px_2']],\n",
    "            dur[[f'{col}_dq_dur']]], axis=1).sort_index()#.dropna().copy()\n",
    "        x['TR Change'] = (x[f'{col}_dq_ER'] / x[f'{col}_dq_ER_2'] - 1)\n",
    "        x['d-o-d sprd pnl'] = (-1) * (x[f'{col}_dq_dur']) * (x[f'{col}_bbg_px'] - x[f'{col}_bbg_px_2']) * 10**(-4)\n",
    "        x['intraday sprd pnl'] = (-1) * (x[f'{col}_dq_dur']) * (x[col] - x[f'{col}_bbg_px_2']) * 10**(-4)\n",
    "        \n",
    "        x['Calculated TR Change'] = x['TR Change'] - x['d-o-d sprd pnl'] + x['intraday sprd pnl']\n",
    "    x['Actual TR Series'] = (1 + x['Calculated TR Change']) * x[f'{col}_dq_ER_2']\n",
    "    x = x[['Actual TR Series']].copy()\n",
    "    x.columns = [col]   \n",
    "    intraday_tr_data = pd.concat([intraday_tr_data, x], axis=1)\n",
    "\n",
    "######################################################################################### Getting ref levels from last close\n",
    "\n",
    "intraday_tr_data1 = intraday_tr_data[intraday_tr_data.index.date<datetime.now().date()].dropna(how='all').copy()\n",
    "last_dict = {}\n",
    "for col in intraday_tr_data1.columns:\n",
    "    last_ref = bbg_datafile.loc[intraday_tr_data1[[col]].dropna().index[-1]][col]\n",
    "    last_date = str(intraday_tr_data1[[col]].dropna().index[-1].date())\n",
    "    last_dict[col] = [intraday_tr_data1[col].dropna().iloc[-1], last_ref, last_date]\n",
    "\n",
    "\n",
    "######################################################################################### calculating today's er series\n",
    "funding = pd.read_excel(\"Funding Rates.xlsx\",index_col=0, parse_dates=True)\n",
    "funding.columns = funding.columns.str.replace(\"GSCBHYEQ\",\"HY Eqty\").str.replace(\"GSCBIGEQ\",\"IG Eqty\")\n",
    "funding['Net Long ESA Funding'] = funding['Net Long SPY Funding']\n",
    "funding['Net Short ESA Funding'] = funding['Net Short SPY Funding']\n",
    "\n",
    "recent_bbg_datafile = bbg_datafile[bbg_datafile.index.date == datetime.now().date()].copy()\n",
    "all_today_er_series = None\n",
    "\n",
    "for col in recent_bbg_datafile.columns:\n",
    "    carry_days = (datetime.now() - pd.to_datetime(last_dict[col][2])).days\n",
    "    x = recent_bbg_datafile[[col]].dropna().copy()\n",
    "    \n",
    "    first_run = False\n",
    "    if col==\"ESA\":\n",
    "        first_run = True\n",
    "    elif dict_map[col][0] == \"Eq\":\n",
    "        first_run = True\n",
    "        \n",
    "    if first_run:\n",
    "        rate = funding[[item for item in funding.columns if col == item.split(\" \",2)[2].rsplit(\" \",1)[0]]].dropna().iloc[-1]\n",
    "        rate = rate.mean()   ############ etf funding rate\n",
    "        x = (last_dict[col][0])*((x/last_dict[col][1])-(rate/100)*(carry_days/360))\n",
    "    elif dict_map[col][4] == \"Yes\":\n",
    "        x = (last_dict[col][0])*(1 - dur[f'{col}_dq_dur'].iloc[-1]*(x-last_dict[col][1])*(10**(-4))+(dict_map[col][3]/100)*(carry_days/360))\n",
    "    elif dict_map[col][0] == \"CDX\":\n",
    "        x = (last_dict[col][0])*(1 + (x-last_dict[col][1])*(10**(-2))+(dict_map[col][3]/100)*(carry_days/360))\n",
    "\n",
    "    all_today_er_series = pd.concat([all_today_er_series, x], axis=1)\n",
    "all_intraday_er_series = pd.concat([intraday_tr_data1, all_today_er_series]).sort_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d53d2a3-7e40-4dd2-832b-1cbab3ada7af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dict_models = {\n",
    "    # 1 : [\"Intraday\",252,252,'A (Intraday; 12M)'],\n",
    "    # 2 : [\"Intraday\",315,315,'B (Intraday; 15M)'],\n",
    "    3 : [\"Intraday\",378,378,'C (Intraday; 18M)'],\n",
    "}\n",
    "\n",
    "def x_model(model_num, models_list, diff_var, calc_method):\n",
    "    all_zplots = None\n",
    "    val = []\n",
    "    \n",
    "    for global_model in models_list:    \n",
    "        model_Y = global_model[0]\n",
    "        model_X = global_model[1]\n",
    "        zscore_Y = global_model[2]\n",
    "        zscore_X = global_model[3]\n",
    "    \n",
    "        backtest_start_date = pd.to_datetime('2021-12-01')\n",
    "        \n",
    "        zscore_vars = [model_Y, zscore_Y] + model_X + zscore_X\n",
    "        zscore_vars = list(set(zscore_vars))\n",
    "        \n",
    "        if 'ESA' in zscore_vars:\n",
    "            zscore_vars_start_time = '07:30:00'\n",
    "            zscore_vars_end_time = '20:00:00'\n",
    "    \n",
    "        # elif ('ITRX XOVER 5Y' in zscore_vars) and ('CDX HY 5Y' in zscore_vars):\n",
    "        #     zscore_vars_start_time = '07:15:00'\n",
    "        #     zscore_vars_end_time = min([dict_map[item][2] for item in zscore_vars])\n",
    "    \n",
    "        else:\n",
    "            zscore_vars_start_time = max([dict_map[item][1] for item in zscore_vars])\n",
    "            zscore_vars_end_time = min([dict_map[item][2] for item in zscore_vars])\n",
    "        \n",
    "        ################################## Beta Calculation\n",
    "\n",
    "        # if len(model_X) == 1:\n",
    "        #     er_Y = f'ER {model_Y}'\n",
    "        #     er_X = f'ER {model_X[0]}'\n",
    "        #     er_data = pd.read_csv(\"All ER.csv\")\n",
    "        #     er_data.columns = ['Date'] + list(er_data.columns)[1:]\n",
    "        #     er_data['Date'] = pd.to_datetime(er_data['Date'])\n",
    "        #     er_data = er_data.set_index('Date')\n",
    "        #     er_data = er_data.sort_index()\n",
    "        #     beta = er_data[[er_Y, er_X]].dropna()\n",
    "        #     beta = beta.resample('W').last()\n",
    "        #     beta = np.log(beta)\n",
    "        #     beta = beta.diff().dropna()\n",
    "        #     beta['Beta1'] = [np.nan] * len(beta)\n",
    "        #     beta['Beta2'] = [np.nan] * len(beta)\n",
    "            \n",
    "        #     for i in range(len(beta)-24+1):\n",
    "        #         reg_X = beta[er_X].iloc[i:i+24]\n",
    "        #         reg_Y = beta[er_Y].iloc[i:i+24]\n",
    "        #         model = sm.OLS(reg_Y, sm.add_constant(reg_X)).fit() \n",
    "        #         beta.iloc[i+23,2] = model.params.iloc[1]\n",
    "            \n",
    "        #         model = sm.OLS(reg_X, sm.add_constant(reg_Y)).fit() \n",
    "        #         beta.iloc[i+23,3] = model.params.iloc[1]\n",
    "            \n",
    "        #     beta['Beta1'] = beta['Beta1'].rolling(104).mean()\n",
    "        #     beta['Beta2'] = beta['Beta2'].rolling(104).mean()\n",
    "        #     beta['Beta'] = 0.5*(beta['Beta1'] + 1/ beta['Beta2'])\n",
    "        #     beta = beta[['Beta']].dropna()\n",
    "        # else:\n",
    "        #     ############################################################# Update this beta calculation\n",
    "    \n",
    "        #     b1 = pd.read_csv(\"All Basis Trade Betas.csv\")\n",
    "        #     b1.columns = ['Date'] + list(b1.columns)[1:]\n",
    "        #     b1 = b1.set_index('Date')\n",
    "        #     beta = b1[[f'{model_Y}_{model_X[0]}_{model_X[1]}']]\n",
    "        #     beta.columns = ['Beta']\n",
    "        #     beta['Coef1'] = beta['Beta'].apply(lambda x: eval(x)[0])\n",
    "        #     beta['Coef2'] = beta['Beta'].apply(lambda x: eval(x)[1])\n",
    "        #     beta.index = pd.to_datetime(beta.index)\n",
    "            \n",
    "        # # beta = beta.resample(sampling_freq).first().ffill()\n",
    "        # beta = beta.resample(\"1min\").first().ffill()\n",
    "        \n",
    "        beta = None\n",
    "        \n",
    "        ######################################## Getting data from the master file......\n",
    "        if calc_method == \"Price\":\n",
    "            df = bbg_datafile.copy()    \n",
    "        elif calc_method == \"Return\":\n",
    "            df = all_intraday_er_series.copy()\n",
    "        \n",
    "        zscore_df = df[zscore_vars].between_time(zscore_vars_start_time, zscore_vars_end_time).copy()\n",
    "        zscore_df3 = zscore_df.copy()\n",
    "        valid_dates = zscore_df3.index.date\n",
    "        zscore_df3 = zscore_df3.iloc[-6000:].resample(\"1min\").last().ffill().copy()\n",
    "        zscore_df3 = zscore_df3[zscore_vars].between_time(zscore_vars_start_time, zscore_vars_end_time).dropna().copy()\n",
    "        zscore_df3 = zscore_df3[pd.Series(zscore_df3.index.date, index=zscore_df3.index).isin(valid_dates)]\n",
    "        zscore_df3 = zscore_df3[zscore_df3.index <= pd.to_datetime(bbg_time)]\n",
    "\n",
    "        start_check = pd.to_datetime(zscore_vars_start_time) - timedelta(minutes=7)\n",
    "        start_check = str(start_check.time())\n",
    "        zscore_df = zscore_df.resample(\"10min\", offset=\"5min\").last().ffill().copy()\n",
    "        zscore_df = zscore_df[zscore_vars].between_time(start_check, zscore_vars_end_time).dropna().copy()\n",
    "        zscore_df = zscore_df[pd.Series(zscore_df.index.date, index=zscore_df.index).isin(valid_dates)]\n",
    "        zscore_df = zscore_df[zscore_df.index >= backtest_start_date]\n",
    "        zscore_df = zscore_df[zscore_df.index <= pd.to_datetime(bbg_time)]\n",
    "        \n",
    "        check_later = zscore_df.copy()\n",
    "        sampling_multiplier = len(set(list(check_later.index.time)))\n",
    "        \n",
    "        \n",
    "        ################################## ZScore Calculation Start : Convert Sprd to PX series\n",
    "        \n",
    "        if calc_method == \"Price\":\n",
    "            zscore_df1 = zscore_df.copy()\n",
    "            df = all_dq_dur.copy()\n",
    "            df.columns = df.columns.str.replace(\" Dur\",\"\")\n",
    "            \n",
    "            last_dq_date = df.index[-1]\n",
    "            last_value = df.iloc[-1,0]\n",
    "            \n",
    "            df.loc[ last_dq_date + timedelta(days=1) ] = last_value\n",
    "            df.loc[ last_dq_date + timedelta(days=2) ] = last_value\n",
    "            \n",
    "            df = df.resample(\"1min\").first().ffill().dropna()\n",
    "            dq_dur = df.copy()\n",
    "            \n",
    "            for col in zscore_df1.columns:\n",
    "                if col in dq_dur.columns:\n",
    "                    zscore_df1[f'{col} Dur'] = dq_dur[col]\n",
    "                    zscore_df1[f'{col} Dur'] = zscore_df1[f'{col} Dur'].shift(1)\n",
    "                    zscore_df1[f'Diff {col}'] = zscore_df1[col].diff()\n",
    "                    zscore_df1 = zscore_df1.dropna()\n",
    "                    zscore_df1[f'{col} Daily PX Change'] = -1 * zscore_df1[f'Diff {col}'] * zscore_df1[f'{col} Dur'] *10**(-4)\n",
    "                    zscore_df1[f'{col} Sum PX'] = zscore_df1[f'{col} Daily PX Change'].cumsum()\n",
    "                    zscore_df1[col] = zscore_df1[f'{col} Sum PX']\n",
    "                    zscore_df1 = zscore_df1[zscore_df.columns].copy()\n",
    "        elif calc_method == \"Return\":\n",
    "            zscore_df1 = zscore_df.copy()\n",
    "        \n",
    "        ################################## ZScore Calculation: Differencing and converting to ZScores\n",
    "        \n",
    "        zscore_df = zscore_df1[zscore_df1.index >= backtest_start_date].copy()\n",
    "        \n",
    "        col_list = zscore_df.columns\n",
    "        for period in diff_var:\n",
    "            for col in col_list:\n",
    "                zscore_df[f'{col}_{period}W'] = zscore_df[col].diff(sampling_multiplier*5*period)\n",
    "        \n",
    "        model_lookback = sampling_multiplier*dict_models[model_num][1]\n",
    "        model_lookback_res = sampling_multiplier*dict_models[model_num][2]\n",
    "        \n",
    "        zscore_df = zscore_df.dropna().copy()\n",
    "        zscore_df2 = zscore_df.copy()\n",
    "    \n",
    "        for period in diff_var:\n",
    "            i = len(zscore_df) - model_lookback\n",
    "            reg_Y = zscore_df[[f'{zscore_Y}_{period}W']].iloc[i:i+model_lookback]\n",
    "            reg_X = zscore_df[[item + f\"_{period}W\" for item in zscore_X]].iloc[i:i+model_lookback]                        \n",
    "            model = sm.OLS(reg_Y,sm.add_constant(reg_X)).fit()\n",
    "            # x = (model.resid - model.resid.rolling(model_lookback_res).mean())/model.resid.rolling(model_lookback_res).std()\n",
    "            x = (model.resid - model.resid.mean())/model.resid.std()\n",
    "            zscore_df.loc[zscore_df.index[i+model_lookback-1],f'{period}W_ZScore'] = x.iloc[-1]\n",
    "        \n",
    "        zscore_df['Avg. ZScore'] = zscore_df[[col for col in zscore_df.columns if col.endswith(\"_ZScore\")]].mean(axis=1)\n",
    "        zscore_df = zscore_df[['Avg. ZScore']]\n",
    "    \n",
    "        bt_df = pd.concat([check_later[[model_Y] + model_X],zscore_df],axis=1).dropna()\n",
    "        bt_df = pd.concat([bt_df,beta],axis=1).dropna()\n",
    "        \n",
    "        zplot = bt_df[['Avg. ZScore']].copy()  \n",
    "        zscore_df3 = zscore_df3.dropna()\n",
    "        val += [zscore_df3.index[-1]]\n",
    "        \n",
    "        if calc_method == \"Price\":\n",
    "            if len(model_X)==1:\n",
    "                zplot.columns = [f'{model_Y}({zscore_df3.iloc[-1][model_Y]}) vs. {model_X[0]}({zscore_df3.\\\n",
    "                iloc[-1][model_X[0]]}) ZScore: {zplot.iloc[-1,0]:.2f}']\n",
    "            else:\n",
    "                zplot.columns = [f'{model_Y}({zscore_df3.\\\n",
    "                iloc[-1][model_Y]}) vs. {model_X}({zscore_df3.iloc[-1][model_X[0]]} & {zscore_df3.\\\n",
    "                iloc[-1][model_X[1]]}) ZScore: {zplot.iloc[-1,0]:.2f}']\n",
    "        \n",
    "        elif calc_method == \"Return\":\n",
    "            \n",
    "            px_sprd_ref = bbg_datafile.iloc[-9000:].copy()\n",
    "            px_sprd_ref = px_sprd_ref.resample(\"1min\").last().ffill().sort_index().copy()\n",
    "            \n",
    "            if len(model_X)==1:\n",
    "                zplot.columns = [f'{model_Y}({px_sprd_ref.loc[zscore_df3.index[-1], model_Y]}) vs. {model_X[0]}({px_sprd_ref.\\\n",
    "                    loc[zscore_df3.index[-1], model_X[0]]}) ZScore: {zplot.iloc[-1,0]:.2f}']\n",
    "            else:\n",
    "                zplot.columns = [f'{model_Y}({px_sprd_ref.\\\n",
    "                    loc[zscore_df3.index[-1], model_Y]}) vs. {model_X}({px_sprd_ref.loc[zscore_df3.index[-1], model_X[0]]} & {px_sprd_ref.\\\n",
    "                    loc[zscore_df3.index[-1], model_X[1]]}) ZScore: {zplot.iloc[-1,0]:.2f}']\n",
    "\n",
    "        all_zplots = pd.concat([all_zplots, zplot],axis=1)\n",
    "        zplot = all_zplots.copy()\n",
    "    return zplot, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "548e4771-c543-40df-a1f6-3432d068c63a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7c816_row0_col4 {\n",
       "  background-color: rgba(213,238,226,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row0_col5 {\n",
       "  background-color: rgba(238,174,161,0.75);\n",
       "}\n",
       "#T_7c816_row1_col4 {\n",
       "  background-color: rgba(150,212,182,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row1_col5 {\n",
       "  background-color: rgba(251,239,236,0.75);\n",
       "}\n",
       "#T_7c816_row2_col0, #T_7c816_row2_col1, #T_7c816_row2_col2, #T_7c816_row2_col3, #T_7c816_row2_col6, #T_7c816_row2_col7, #T_7c816_row7_col0, #T_7c816_row7_col1, #T_7c816_row7_col2, #T_7c816_row7_col3, #T_7c816_row7_col6, #T_7c816_row7_col7, #T_7c816_row13_col0, #T_7c816_row13_col1, #T_7c816_row13_col2, #T_7c816_row13_col3, #T_7c816_row13_col6, #T_7c816_row13_col7, #T_7c816_row15_col0, #T_7c816_row15_col1, #T_7c816_row15_col2, #T_7c816_row15_col3, #T_7c816_row15_col6, #T_7c816_row15_col7, #T_7c816_row17_col0, #T_7c816_row17_col1, #T_7c816_row17_col2, #T_7c816_row17_col3, #T_7c816_row17_col6, #T_7c816_row17_col7, #T_7c816_row21_col0, #T_7c816_row21_col1, #T_7c816_row21_col2, #T_7c816_row21_col3, #T_7c816_row21_col6, #T_7c816_row21_col7 {\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row2_col4 {\n",
       "  background-color: rgba(87,187,138,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row2_col5 {\n",
       "  background-color: rgba(240,185,174,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row3_col4 {\n",
       "  background-color: rgba(220,240,230,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row3_col5, #T_7c816_row4_col5 {\n",
       "  background-color: rgba(247,220,214,0.75);\n",
       "}\n",
       "#T_7c816_row4_col4, #T_7c816_row18_col4 {\n",
       "  background-color: rgba(210,237,224,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row5_col4 {\n",
       "  background-color: rgba(239,182,169,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row5_col5 {\n",
       "  background-color: rgba(239,182,170,0.75);\n",
       "}\n",
       "#T_7c816_row6_col4 {\n",
       "  background-color: rgba(239,180,168,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row6_col5 {\n",
       "  background-color: rgba(245,207,199,0.75);\n",
       "}\n",
       "#T_7c816_row7_col4 {\n",
       "  background-color: rgba(249,226,222,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row7_col5 {\n",
       "  background-color: rgba(249,229,225,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row8_col4 {\n",
       "  background-color: rgba(253,248,247,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row8_col5 {\n",
       "  background-color: rgba(148,211,180,0.75);\n",
       "}\n",
       "#T_7c816_row9_col4 {\n",
       "  background-color: rgba(242,249,246,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row9_col5 {\n",
       "  background-color: rgba(142,209,176,0.75);\n",
       "}\n",
       "#T_7c816_row10_col4 {\n",
       "  background-color: rgba(230,139,120,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row10_col5 {\n",
       "  background-color: rgba(252,244,242,0.75);\n",
       "}\n",
       "#T_7c816_row11_col4 {\n",
       "  background-color: rgba(230,135,115,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row11_col5 {\n",
       "  background-color: rgba(205,234,220,0.75);\n",
       "}\n",
       "#T_7c816_row12_col4 {\n",
       "  background-color: rgba(249,230,226,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row12_col5 {\n",
       "  background-color: rgba(87,187,138,0.75);\n",
       "}\n",
       "#T_7c816_row13_col4 {\n",
       "  background-color: rgba(241,188,177,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row13_col5 {\n",
       "  background-color: rgba(139,208,174,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row14_col4 {\n",
       "  background-color: rgba(253,247,245,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row14_col5 {\n",
       "  background-color: rgba(243,197,188,0.75);\n",
       "}\n",
       "#T_7c816_row15_col4 {\n",
       "  background-color: rgba(250,231,227,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row15_col5 {\n",
       "  background-color: rgba(243,197,188,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row16_col4 {\n",
       "  background-color: rgba(236,167,152,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row16_col5 {\n",
       "  background-color: rgba(244,203,194,0.75);\n",
       "}\n",
       "#T_7c816_row17_col4 {\n",
       "  background-color: rgba(239,182,169,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row17_col5 {\n",
       "  background-color: rgba(230,135,115,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row18_col5 {\n",
       "  background-color: rgba(251,237,234,0.75);\n",
       "}\n",
       "#T_7c816_row19_col4 {\n",
       "  background-color: rgba(230,136,116,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row19_col5 {\n",
       "  background-color: rgba(234,158,142,0.75);\n",
       "}\n",
       "#T_7c816_row20_col4 {\n",
       "  background-color: rgba(253,249,248,0.75);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_7c816_row20_col5 {\n",
       "  background-color: rgba(248,224,218,0.75);\n",
       "}\n",
       "#T_7c816_row21_col4 {\n",
       "  background-color: rgba(254,252,252,0.75);\n",
       "  font-weight: bold;\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "#T_7c816_row21_col5 {\n",
       "  background-color: rgba(248,223,217,0.75);\n",
       "  border-bottom: 3px solid black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7c816\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_7c816_level0_col0\" class=\"col_heading level0 col0\" colspan=\"8\">05:38 PM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7c816_level1_col0\" class=\"col_heading level1 col0\" >Long Risk</th>\n",
       "      <th id=\"T_7c816_level1_col1\" class=\"col_heading level1 col1\" >Ref</th>\n",
       "      <th id=\"T_7c816_level1_col2\" class=\"col_heading level1 col2\" >Short Risk</th>\n",
       "      <th id=\"T_7c816_level1_col3\" class=\"col_heading level1 col3\" >Ref.</th>\n",
       "      <th id=\"T_7c816_level1_col4\" class=\"col_heading level1 col4\" >PX_Zscore 1/2/3w</th>\n",
       "      <th id=\"T_7c816_level1_col5\" class=\"col_heading level1 col5\" >Rtn_Zscore 6/9/12w</th>\n",
       "      <th id=\"T_7c816_level1_col6\" class=\"col_heading level1 col6\" >Valuation</th>\n",
       "      <th id=\"T_7c816_level1_col7\" class=\"col_heading level1 col7\" >Last Update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row0_col0\" class=\"data row0 col0\" >IG</td>\n",
       "      <td id=\"T_7c816_row0_col1\" class=\"data row0 col1\" >48.945</td>\n",
       "      <td id=\"T_7c816_row0_col2\" class=\"data row0 col2\" >['VCIT', 'IEF']</td>\n",
       "      <td id=\"T_7c816_row0_col3\" class=\"data row0 col3\" >['83.87', '96.28']</td>\n",
       "      <td id=\"T_7c816_row0_col4\" class=\"data row0 col4\" >-0.13</td>\n",
       "      <td id=\"T_7c816_row0_col5\" class=\"data row0 col5\" >1.66</td>\n",
       "      <td id=\"T_7c816_row0_col6\" class=\"data row0 col6\" >IG cheap to ['VCIT', 'IEF']</td>\n",
       "      <td id=\"T_7c816_row0_col7\" class=\"data row0 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row1_col0\" class=\"data row1 col0\" >HY</td>\n",
       "      <td id=\"T_7c816_row1_col1\" class=\"data row1 col1\" >107.6015</td>\n",
       "      <td id=\"T_7c816_row1_col2\" class=\"data row1 col2\" >['HYG', 'IEI']</td>\n",
       "      <td id=\"T_7c816_row1_col3\" class=\"data row1 col3\" >['80.92', '119.31']</td>\n",
       "      <td id=\"T_7c816_row1_col4\" class=\"data row1 col4\" >-0.33</td>\n",
       "      <td id=\"T_7c816_row1_col5\" class=\"data row1 col5\" >0.32</td>\n",
       "      <td id=\"T_7c816_row1_col6\" class=\"data row1 col6\" >HY cheap to ['HYG', 'IEI']</td>\n",
       "      <td id=\"T_7c816_row1_col7\" class=\"data row1 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row2_col0\" class=\"data row2 col0\" >EM</td>\n",
       "      <td id=\"T_7c816_row2_col1\" class=\"data row2 col1\" >98.39</td>\n",
       "      <td id=\"T_7c816_row2_col2\" class=\"data row2 col2\" >['EMB', 'IEF']</td>\n",
       "      <td id=\"T_7c816_row2_col3\" class=\"data row2 col3\" >['95.26', '96.28']</td>\n",
       "      <td id=\"T_7c816_row2_col4\" class=\"data row2 col4\" >-0.53</td>\n",
       "      <td id=\"T_7c816_row2_col5\" class=\"data row2 col5\" >1.43</td>\n",
       "      <td id=\"T_7c816_row2_col6\" class=\"data row2 col6\" >EM cheap to ['EMB', 'IEF']</td>\n",
       "      <td id=\"T_7c816_row2_col7\" class=\"data row2 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row3_col0\" class=\"data row3 col0\" >IG</td>\n",
       "      <td id=\"T_7c816_row3_col1\" class=\"data row3 col1\" >48.95525</td>\n",
       "      <td id=\"T_7c816_row3_col2\" class=\"data row3 col2\" >ESA</td>\n",
       "      <td id=\"T_7c816_row3_col3\" class=\"data row3 col3\" >657.84</td>\n",
       "      <td id=\"T_7c816_row3_col4\" class=\"data row3 col4\" >-0.11</td>\n",
       "      <td id=\"T_7c816_row3_col5\" class=\"data row3 col5\" >0.71</td>\n",
       "      <td id=\"T_7c816_row3_col6\" class=\"data row3 col6\" >IG cheap to ESA</td>\n",
       "      <td id=\"T_7c816_row3_col7\" class=\"data row3 col7\" >25-Sep 05:38 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row4_col0\" class=\"data row4 col0\" >IG</td>\n",
       "      <td id=\"T_7c816_row4_col1\" class=\"data row4 col1\" >48.945</td>\n",
       "      <td id=\"T_7c816_row4_col2\" class=\"data row4 col2\" >SPY</td>\n",
       "      <td id=\"T_7c816_row4_col3\" class=\"data row4 col3\" >658.05</td>\n",
       "      <td id=\"T_7c816_row4_col4\" class=\"data row4 col4\" >-0.14</td>\n",
       "      <td id=\"T_7c816_row4_col5\" class=\"data row4 col5\" >0.72</td>\n",
       "      <td id=\"T_7c816_row4_col6\" class=\"data row4 col6\" >IG cheap to SPY</td>\n",
       "      <td id=\"T_7c816_row4_col7\" class=\"data row4 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row5_col0\" class=\"data row5 col0\" >IG</td>\n",
       "      <td id=\"T_7c816_row5_col1\" class=\"data row5 col1\" >48.945</td>\n",
       "      <td id=\"T_7c816_row5_col2\" class=\"data row5 col2\" >RSP</td>\n",
       "      <td id=\"T_7c816_row5_col3\" class=\"data row5 col3\" >186.72</td>\n",
       "      <td id=\"T_7c816_row5_col4\" class=\"data row5 col4\" >0.65</td>\n",
       "      <td id=\"T_7c816_row5_col5\" class=\"data row5 col5\" >1.50</td>\n",
       "      <td id=\"T_7c816_row5_col6\" class=\"data row5 col6\" >IG rich to RSP</td>\n",
       "      <td id=\"T_7c816_row5_col7\" class=\"data row5 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row6_col0\" class=\"data row6 col0\" >IG</td>\n",
       "      <td id=\"T_7c816_row6_col1\" class=\"data row6 col1\" >48.945</td>\n",
       "      <td id=\"T_7c816_row6_col2\" class=\"data row6 col2\" >IJH</td>\n",
       "      <td id=\"T_7c816_row6_col3\" class=\"data row6 col3\" >64.68</td>\n",
       "      <td id=\"T_7c816_row6_col4\" class=\"data row6 col4\" >0.66</td>\n",
       "      <td id=\"T_7c816_row6_col5\" class=\"data row6 col5\" >0.99</td>\n",
       "      <td id=\"T_7c816_row6_col6\" class=\"data row6 col6\" >IG rich to IJH</td>\n",
       "      <td id=\"T_7c816_row6_col7\" class=\"data row6 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row7_col0\" class=\"data row7 col0\" >IG</td>\n",
       "      <td id=\"T_7c816_row7_col1\" class=\"data row7 col1\" >48.945</td>\n",
       "      <td id=\"T_7c816_row7_col2\" class=\"data row7 col2\" >IG Eqty</td>\n",
       "      <td id=\"T_7c816_row7_col3\" class=\"data row7 col3\" >203.66</td>\n",
       "      <td id=\"T_7c816_row7_col4\" class=\"data row7 col4\" >0.25</td>\n",
       "      <td id=\"T_7c816_row7_col5\" class=\"data row7 col5\" >0.53</td>\n",
       "      <td id=\"T_7c816_row7_col6\" class=\"data row7 col6\" >IG rich to IG Eqty</td>\n",
       "      <td id=\"T_7c816_row7_col7\" class=\"data row7 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row8_col0\" class=\"data row8 col0\" >HY</td>\n",
       "      <td id=\"T_7c816_row8_col1\" class=\"data row8 col1\" >107.6184</td>\n",
       "      <td id=\"T_7c816_row8_col2\" class=\"data row8 col2\" >ESA</td>\n",
       "      <td id=\"T_7c816_row8_col3\" class=\"data row8 col3\" >657.84</td>\n",
       "      <td id=\"T_7c816_row8_col4\" class=\"data row8 col4\" >0.06</td>\n",
       "      <td id=\"T_7c816_row8_col5\" class=\"data row8 col5\" >-0.90</td>\n",
       "      <td id=\"T_7c816_row8_col6\" class=\"data row8 col6\" >HY rich to ESA</td>\n",
       "      <td id=\"T_7c816_row8_col7\" class=\"data row8 col7\" >25-Sep 05:38 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row9_col0\" class=\"data row9 col0\" >HY</td>\n",
       "      <td id=\"T_7c816_row9_col1\" class=\"data row9 col1\" >107.6015</td>\n",
       "      <td id=\"T_7c816_row9_col2\" class=\"data row9 col2\" >SPY</td>\n",
       "      <td id=\"T_7c816_row9_col3\" class=\"data row9 col3\" >658.05</td>\n",
       "      <td id=\"T_7c816_row9_col4\" class=\"data row9 col4\" >-0.04</td>\n",
       "      <td id=\"T_7c816_row9_col5\" class=\"data row9 col5\" >-0.95</td>\n",
       "      <td id=\"T_7c816_row9_col6\" class=\"data row9 col6\" >HY cheap to SPY</td>\n",
       "      <td id=\"T_7c816_row9_col7\" class=\"data row9 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row10_col0\" class=\"data row10 col0\" >HY</td>\n",
       "      <td id=\"T_7c816_row10_col1\" class=\"data row10 col1\" >107.6015</td>\n",
       "      <td id=\"T_7c816_row10_col2\" class=\"data row10 col2\" >RSP</td>\n",
       "      <td id=\"T_7c816_row10_col3\" class=\"data row10 col3\" >186.72</td>\n",
       "      <td id=\"T_7c816_row10_col4\" class=\"data row10 col4\" >1.03</td>\n",
       "      <td id=\"T_7c816_row10_col5\" class=\"data row10 col5\" >0.22</td>\n",
       "      <td id=\"T_7c816_row10_col6\" class=\"data row10 col6\" >HY rich to RSP</td>\n",
       "      <td id=\"T_7c816_row10_col7\" class=\"data row10 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row11_col0\" class=\"data row11 col0\" >HY</td>\n",
       "      <td id=\"T_7c816_row11_col1\" class=\"data row11 col1\" >107.6015</td>\n",
       "      <td id=\"T_7c816_row11_col2\" class=\"data row11 col2\" >IJH</td>\n",
       "      <td id=\"T_7c816_row11_col3\" class=\"data row11 col3\" >64.68</td>\n",
       "      <td id=\"T_7c816_row11_col4\" class=\"data row11 col4\" >1.07</td>\n",
       "      <td id=\"T_7c816_row11_col5\" class=\"data row11 col5\" >-0.42</td>\n",
       "      <td id=\"T_7c816_row11_col6\" class=\"data row11 col6\" >HY rich to IJH</td>\n",
       "      <td id=\"T_7c816_row11_col7\" class=\"data row11 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row12_col0\" class=\"data row12 col0\" >HY</td>\n",
       "      <td id=\"T_7c816_row12_col1\" class=\"data row12 col1\" >107.6015</td>\n",
       "      <td id=\"T_7c816_row12_col2\" class=\"data row12 col2\" >IWM</td>\n",
       "      <td id=\"T_7c816_row12_col3\" class=\"data row12 col3\" >239.31</td>\n",
       "      <td id=\"T_7c816_row12_col4\" class=\"data row12 col4\" >0.22</td>\n",
       "      <td id=\"T_7c816_row12_col5\" class=\"data row12 col5\" >-1.42</td>\n",
       "      <td id=\"T_7c816_row12_col6\" class=\"data row12 col6\" >HY rich to IWM</td>\n",
       "      <td id=\"T_7c816_row12_col7\" class=\"data row12 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row13_col0\" class=\"data row13 col0\" >HY</td>\n",
       "      <td id=\"T_7c816_row13_col1\" class=\"data row13 col1\" >107.6015</td>\n",
       "      <td id=\"T_7c816_row13_col2\" class=\"data row13 col2\" >HY Eqty</td>\n",
       "      <td id=\"T_7c816_row13_col3\" class=\"data row13 col3\" >328.58</td>\n",
       "      <td id=\"T_7c816_row13_col4\" class=\"data row13 col4\" >0.59</td>\n",
       "      <td id=\"T_7c816_row13_col5\" class=\"data row13 col5\" >-0.98</td>\n",
       "      <td id=\"T_7c816_row13_col6\" class=\"data row13 col6\" >HY rich to HY Eqty</td>\n",
       "      <td id=\"T_7c816_row13_col7\" class=\"data row13 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row14_col0\" class=\"data row14 col0\" >MAIN</td>\n",
       "      <td id=\"T_7c816_row14_col1\" class=\"data row14 col1\" >50.834</td>\n",
       "      <td id=\"T_7c816_row14_col2\" class=\"data row14 col2\" >SX5E</td>\n",
       "      <td id=\"T_7c816_row14_col3\" class=\"data row14 col3\" >5444.89</td>\n",
       "      <td id=\"T_7c816_row14_col4\" class=\"data row14 col4\" >0.07</td>\n",
       "      <td id=\"T_7c816_row14_col5\" class=\"data row14 col5\" >1.18</td>\n",
       "      <td id=\"T_7c816_row14_col6\" class=\"data row14 col6\" >MAIN rich to SX5E</td>\n",
       "      <td id=\"T_7c816_row14_col7\" class=\"data row14 col7\" >25-Sep 11:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row15_col0\" class=\"data row15 col0\" >XOVER</td>\n",
       "      <td id=\"T_7c816_row15_col1\" class=\"data row15 col1\" >247.957</td>\n",
       "      <td id=\"T_7c816_row15_col2\" class=\"data row15 col2\" >SX5E</td>\n",
       "      <td id=\"T_7c816_row15_col3\" class=\"data row15 col3\" >5444.89</td>\n",
       "      <td id=\"T_7c816_row15_col4\" class=\"data row15 col4\" >0.21</td>\n",
       "      <td id=\"T_7c816_row15_col5\" class=\"data row15 col5\" >1.18</td>\n",
       "      <td id=\"T_7c816_row15_col6\" class=\"data row15 col6\" >XOVER rich to SX5E</td>\n",
       "      <td id=\"T_7c816_row15_col7\" class=\"data row15 col7\" >25-Sep 11:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row16_col0\" class=\"data row16 col0\" >MAIN</td>\n",
       "      <td id=\"T_7c816_row16_col1\" class=\"data row16 col1\" >50.834</td>\n",
       "      <td id=\"T_7c816_row16_col2\" class=\"data row16 col2\" >IG</td>\n",
       "      <td id=\"T_7c816_row16_col3\" class=\"data row16 col3\" >48.734</td>\n",
       "      <td id=\"T_7c816_row16_col4\" class=\"data row16 col4\" >0.78</td>\n",
       "      <td id=\"T_7c816_row16_col5\" class=\"data row16 col5\" >1.07</td>\n",
       "      <td id=\"T_7c816_row16_col6\" class=\"data row16 col6\" >MAIN rich to IG</td>\n",
       "      <td id=\"T_7c816_row16_col7\" class=\"data row16 col7\" >25-Sep 11:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row17_col0\" class=\"data row17 col0\" >XOVER</td>\n",
       "      <td id=\"T_7c816_row17_col1\" class=\"data row17 col1\" >247.957</td>\n",
       "      <td id=\"T_7c816_row17_col2\" class=\"data row17 col2\" >HY</td>\n",
       "      <td id=\"T_7c816_row17_col3\" class=\"data row17 col3\" >107.6304</td>\n",
       "      <td id=\"T_7c816_row17_col4\" class=\"data row17 col4\" >0.65</td>\n",
       "      <td id=\"T_7c816_row17_col5\" class=\"data row17 col5\" >2.48</td>\n",
       "      <td id=\"T_7c816_row17_col6\" class=\"data row17 col6\" >XOVER rich to HY</td>\n",
       "      <td id=\"T_7c816_row17_col7\" class=\"data row17 col7\" >25-Sep 11:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row18_col0\" class=\"data row18 col0\" >EMB</td>\n",
       "      <td id=\"T_7c816_row18_col1\" class=\"data row18 col1\" >95.26</td>\n",
       "      <td id=\"T_7c816_row18_col2\" class=\"data row18 col2\" >EEM</td>\n",
       "      <td id=\"T_7c816_row18_col3\" class=\"data row18 col3\" >52.81</td>\n",
       "      <td id=\"T_7c816_row18_col4\" class=\"data row18 col4\" >-0.14</td>\n",
       "      <td id=\"T_7c816_row18_col5\" class=\"data row18 col5\" >0.37</td>\n",
       "      <td id=\"T_7c816_row18_col6\" class=\"data row18 col6\" >EMB cheap to EEM</td>\n",
       "      <td id=\"T_7c816_row18_col7\" class=\"data row18 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row19_col0\" class=\"data row19 col0\" >EM</td>\n",
       "      <td id=\"T_7c816_row19_col1\" class=\"data row19 col1\" >98.39201</td>\n",
       "      <td id=\"T_7c816_row19_col2\" class=\"data row19 col2\" >IG</td>\n",
       "      <td id=\"T_7c816_row19_col3\" class=\"data row19 col3\" >48.95525</td>\n",
       "      <td id=\"T_7c816_row19_col4\" class=\"data row19 col4\" >1.06</td>\n",
       "      <td id=\"T_7c816_row19_col5\" class=\"data row19 col5\" >1.99</td>\n",
       "      <td id=\"T_7c816_row19_col6\" class=\"data row19 col6\" >EM rich to IG</td>\n",
       "      <td id=\"T_7c816_row19_col7\" class=\"data row19 col7\" >25-Sep 05:38 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row20_col0\" class=\"data row20 col0\" >EM</td>\n",
       "      <td id=\"T_7c816_row20_col1\" class=\"data row20 col1\" >98.419</td>\n",
       "      <td id=\"T_7c816_row20_col2\" class=\"data row20 col2\" >XOVER</td>\n",
       "      <td id=\"T_7c816_row20_col3\" class=\"data row20 col3\" >247.957</td>\n",
       "      <td id=\"T_7c816_row20_col4\" class=\"data row20 col4\" >0.05</td>\n",
       "      <td id=\"T_7c816_row20_col5\" class=\"data row20 col5\" >0.64</td>\n",
       "      <td id=\"T_7c816_row20_col6\" class=\"data row20 col6\" >EM rich to XOVER</td>\n",
       "      <td id=\"T_7c816_row20_col7\" class=\"data row20 col7\" >25-Sep 11:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7c816_row21_col0\" class=\"data row21 col0\" >EM</td>\n",
       "      <td id=\"T_7c816_row21_col1\" class=\"data row21 col1\" >98.39</td>\n",
       "      <td id=\"T_7c816_row21_col2\" class=\"data row21 col2\" >EEM</td>\n",
       "      <td id=\"T_7c816_row21_col3\" class=\"data row21 col3\" >52.81</td>\n",
       "      <td id=\"T_7c816_row21_col4\" class=\"data row21 col4\" >0.02</td>\n",
       "      <td id=\"T_7c816_row21_col5\" class=\"data row21 col5\" >0.66</td>\n",
       "      <td id=\"T_7c816_row21_col6\" class=\"data row21 col6\" >EM rich to EEM</td>\n",
       "      <td id=\"T_7c816_row21_col7\" class=\"data row21 col7\" >25-Sep 03:59 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2af03c4f9e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m     98\u001b[39m times_list += t1\n\u001b[32m    100\u001b[39m models_list = [ \n\u001b[32m    101\u001b[39m \n\u001b[32m    102\u001b[39m     [\u001b[33m'\u001b[39m\u001b[33mCDX IG 5Y\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33mESA\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mCDX IG 5Y\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33mESA\u001b[39m\u001b[33m'\u001b[39m],],\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m \n\u001b[32m    122\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m l1, t1 = \u001b[43mx_model\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m l2 = pd.concat([l2,l1],axis=\u001b[32m1\u001b[39m)\n\u001b[32m    125\u001b[39m times_list += t1  \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 125\u001b[39m, in \u001b[36mx_model\u001b[39m\u001b[34m(model_num, models_list, diff_var, calc_method)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m zscore_df1.columns:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m dq_dur.columns:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m         \u001b[43mzscore_df1\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcol\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m Dur\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = dq_dur[col]\n\u001b[32m    126\u001b[39m         zscore_df1[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Dur\u001b[39m\u001b[33m'\u001b[39m] = zscore_df1[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Dur\u001b[39m\u001b[33m'\u001b[39m].shift(\u001b[32m1\u001b[39m)\n\u001b[32m    127\u001b[39m         zscore_df1[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDiff \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = zscore_df1[col].diff()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4308\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4310\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4311\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4514\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4515\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4516\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4517\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4522\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4523\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4524\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4527\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4528\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4529\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4530\u001b[39m     ):\n\u001b[32m   4531\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4532\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5263\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5261\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Series):\n\u001b[32m   5262\u001b[39m         value = Series(value)\n\u001b[32m-> \u001b[39m\u001b[32m5263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m   5266\u001b[39m     com.require_length_match(value, \u001b[38;5;28mself\u001b[39m.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:12687\u001b[39m, in \u001b[36m_reindex_for_setitem\u001b[39m\u001b[34m(value, index)\u001b[39m\n\u001b[32m  12685\u001b[39m \u001b[38;5;66;03m# GH#4107\u001b[39;00m\n\u001b[32m  12686\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m> \u001b[39m\u001b[32m12687\u001b[39m     reindexed_value = \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m._values\n\u001b[32m  12688\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m  12689\u001b[39m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[32m  12690\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value.index.is_unique:\n\u001b[32m  12691\u001b[39m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:5153\u001b[39m, in \u001b[36mSeries.reindex\u001b[39m\u001b[34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5136\u001b[39m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[32m   5137\u001b[39m     NDFrame.reindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m   5138\u001b[39m     klass=_shared_doc_kwargs[\u001b[33m\"\u001b[39m\u001b[33mklass\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   5151\u001b[39m     tolerance=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5152\u001b[39m ) -> Series:\n\u001b[32m-> \u001b[39m\u001b[32m5153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:5610\u001b[39m, in \u001b[36mNDFrame.reindex\u001b[39m\u001b[34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5607\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reindex_multi(axes, copy, fill_value)\n\u001b[32m   5609\u001b[39m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5610\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m   5612\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mreindex\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:5633\u001b[39m, in \u001b[36mNDFrame._reindex_axes\u001b[39m\u001b[34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[39m\n\u001b[32m   5630\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   5632\u001b[39m ax = \u001b[38;5;28mself\u001b[39m._get_axis(a)\n\u001b[32m-> \u001b[39m\u001b[32m5633\u001b[39m new_index, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[32m   5635\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5637\u001b[39m axis = \u001b[38;5;28mself\u001b[39m._get_axis_number(a)\n\u001b[32m   5638\u001b[39m obj = obj._reindex_with_indexers(\n\u001b[32m   5639\u001b[39m     {axis: [new_index, indexer]},\n\u001b[32m   5640\u001b[39m     fill_value=fill_value,\n\u001b[32m   5641\u001b[39m     copy=copy,\n\u001b[32m   5642\u001b[39m     allow_dups=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   5643\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4422\u001b[39m, in \u001b[36mIndex.reindex\u001b[39m\u001b[34m(self, target, method, level, limit, tolerance)\u001b[39m\n\u001b[32m   4420\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4421\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_as_unique:\n\u001b[32m-> \u001b[39m\u001b[32m4422\u001b[39m         indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4423\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\n\u001b[32m   4424\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4425\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_multi:\n\u001b[32m   4426\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot handle a non-unique multi-index!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3820\u001b[39m, in \u001b[36mIndex.get_indexer\u001b[39m\u001b[34m(self, target, method, limit, tolerance)\u001b[39m\n\u001b[32m   3817\u001b[39m         \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3820\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   3821\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mget_indexer\u001b[39m(\n\u001b[32m   3822\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   3823\u001b[39m     target,\n\u001b[32m   3824\u001b[39m     method: ReindexMethod | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3825\u001b[39m     limit: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3826\u001b[39m     tolerance=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3827\u001b[39m ) -> npt.NDArray[np.intp]:\n\u001b[32m   3828\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3829\u001b[39m \u001b[33;03m    Compute indexer and mask for new index given the current index.\u001b[39;00m\n\u001b[32m   3830\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3876\u001b[39m \u001b[33;03m    and ``x`` is marked by -1, as it is not in ``index``.\u001b[39;00m\n\u001b[32m   3877\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   3878\u001b[39m     method = clean_reindex_fill_method(method)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "display(None, display_id=\"DFA\")\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ################################################################## Capture PX; check if market is live and attach\n",
    "    px = blp.bdp(tickers=all_bbg_tickers, flds='PX_LAST').T\n",
    "    bbg_time = datetime.now()\n",
    "    px.index= [f'{bbg_time}']\n",
    "    px.index = pd.to_datetime(px.index)\n",
    "    px = px.resample(\"1min\").last()\n",
    "    px.loc[px.index[0],'ESA INDEX'] = round(blp.bdp(tickers=\"ESA INDEX\", flds=\"PX_LAST\").iloc[0,0] * (spx_val/esa_val),2)\n",
    "    \n",
    "    if first_current_date_esa_close or bbg_time <= pd.to_datetime(\"09:33:00\"):\n",
    "        live_list = ['CDX IG CDSI GEN 5Y CORP','ITRX EUR CDSI GEN 5Y CORP', 'RSP US EQUITY','SX5E INDEX','ESA INDEX']\n",
    "        mkt_live = blp.bdh(tickers=live_list, flds='px_last', start_date = datetime.now()-timedelta(days=5))\n",
    "        mkt_live.columns = live_list\n",
    "        first_current_date_esa_close = False\n",
    "    \n",
    "    for col in px.columns:\n",
    "        if col == \"ESA INDEX\" and bbg_time.date() in mkt_live[live_dict[col]].dropna().index:\n",
    "            if bbg_time.time() >= pd.to_datetime(\"07:30\").time() and\\\n",
    "            bbg_time.time() <= (pd.to_datetime(\"20:00\") + timedelta(minutes=1)).time():\n",
    "                continue\n",
    "            else:\n",
    "                px.loc[px.index[0],col] = np.nan\n",
    "        elif bbg_time.date() in mkt_live[live_dict[col]].dropna().index and\\\n",
    "        bbg_time.time() >= pd.to_datetime(dict_map[reverse_dict[col]][1]).time() and\\\n",
    "        bbg_time.time() <= (pd.to_datetime(dict_map[reverse_dict[col]][2]) + timedelta(minutes=1)).time():\n",
    "            continue\n",
    "        else:\n",
    "            px.loc[px.index[0],col] = np.nan\n",
    "    px.columns = [reverse_dict[item] for item in px.columns]\n",
    "    bbg_datafile = pd.concat([bbg_datafile, px]).sort_index().copy()\n",
    "    bbg_datafile = bbg_datafile.resample(\"1min\").last().dropna(how='all').copy()\n",
    "\n",
    "    ################################################################## Convert PX to ER series and attach\n",
    "    current_er_series = None\n",
    "\n",
    "    for col in px.columns:\n",
    "        carry_days = (datetime.now() - pd.to_datetime(last_dict[col][2])).days\n",
    "        x = px[[col]].dropna().copy()\n",
    "\n",
    "        first_run = False\n",
    "        if col==\"ESA\":\n",
    "            first_run = True\n",
    "        elif dict_map[col][0] == \"Eq\":\n",
    "            first_run = True\n",
    "            \n",
    "        if first_run:\n",
    "            rate = funding[[item for item in funding.columns if col == item.split(\" \",2)[2].rsplit(\" \",1)[0]]].dropna().iloc[-1]\n",
    "            rate = rate.mean()   ############ etf funding rate\n",
    "            x = (last_dict[col][0])*((x/last_dict[col][1])-(rate/100)*(carry_days/360))\n",
    "        elif dict_map[col][4] == \"Yes\":\n",
    "            x = (last_dict[col][0])*(1 - dur[f'{col}_dq_dur'].iloc[-1]*(x-last_dict[col][1])*(10**(-4))+(dict_map[col][3]/100)*(carry_days/360))\n",
    "        elif dict_map[col][0] == \"CDX\":\n",
    "            x = (last_dict[col][0])*(1 + (x-last_dict[col][1])*(10**(-2))+(dict_map[col][3]/100)*(carry_days/360))\n",
    "        \n",
    "        current_er_series = pd.concat([current_er_series, x], axis=1)\n",
    "    all_intraday_er_series = pd.concat([all_intraday_er_series, current_er_series]).sort_index().copy()\n",
    "    all_intraday_er_series = all_intraday_er_series.resample(\"1min\").last().dropna(how='all').copy()\n",
    "    \n",
    "    last_update_time = all_intraday_er_series.copy()\n",
    "    \n",
    "    ##################################################################  Regressions starts from here\n",
    "    all_zscore_values = []\n",
    "\n",
    "    for diff_list in [[1,2,3],[6,9,12]]:        \n",
    "        times_list = []\n",
    "\n",
    "        if diff_list == [1,2,3]:\n",
    "            calc = \"Price\"\n",
    "        elif diff_list == [6,9,12]:\n",
    "            calc = \"Return\"            \n",
    "        \n",
    "        # model_Y, model_X (specify as a list) ### We trade these\n",
    "        # zscore_Y, zscore_X (specify as a list) ### We use these only for generating the zscore; names are taken from BBG datafile\n",
    "        \n",
    "        models_list = [\n",
    "            ['CDX IG 5Y', ['VCIT','IEF'], 'CDX IG 5Y', ['VCIT','IEF'],],\n",
    "        ]\n",
    "        l1, t1 = x_model(3, models_list, diff_list, calc)\n",
    "        l2 = l1.copy()\n",
    "        times_list += t1\n",
    "           \n",
    "        models_list = [ \n",
    "            ['CDX HY 5Y', ['HYG','IEI'], 'CDX HY 5Y', ['HYG','IEI'],],\n",
    "            \n",
    "        ]\n",
    "        l1, t1 = x_model(3, models_list, diff_list, calc)\n",
    "        l2 = pd.concat([l2,l1],axis=1)\n",
    "        times_list += t1\n",
    "        \n",
    "        models_list = [ \n",
    "            ['CDX EM 5Y', ['EMB','IEF'], 'CDX EM 5Y', ['EMB','IEF'],],\n",
    "        ]\n",
    "        l1, t1 = x_model(3, models_list, diff_list, calc)\n",
    "        l2 = pd.concat([l2,l1],axis=1)\n",
    "        times_list += t1\n",
    "        \n",
    "        models_list = [ \n",
    "        \n",
    "            ['CDX IG 5Y', ['ESA'], 'CDX IG 5Y', ['ESA'],],\n",
    "            ['CDX IG 5Y', ['SPY'], 'CDX IG 5Y', ['SPY'],],\n",
    "            ['CDX IG 5Y', ['RSP'], 'CDX IG 5Y', ['RSP'],],\n",
    "            ['CDX IG 5Y', ['IJH'], 'CDX IG 5Y', ['IJH'],],\n",
    "            ['CDX IG 5Y', ['IG Eqty'], 'CDX IG 5Y', ['IG Eqty'],],\n",
    "            \n",
    "            ['CDX HY 5Y', ['ESA'], 'CDX HY 5Y', ['ESA'],],\n",
    "            ['CDX HY 5Y', ['SPY'], 'CDX HY 5Y', ['SPY'],],\n",
    "            ['CDX HY 5Y', ['RSP'], 'CDX HY 5Y', ['RSP'],],\n",
    "            ['CDX HY 5Y', ['IJH'], 'CDX HY 5Y', ['IJH'],],\n",
    "            # ['CDX HY 5Y', ['RTY'], 'CDX HY 5Y', ['RTY'],],\n",
    "            ['CDX HY 5Y', ['IWM'], 'CDX HY 5Y', ['IWM'],],\n",
    "            ['CDX HY 5Y', ['HY Eqty'], 'CDX HY 5Y', ['HY Eqty'],],\n",
    "            \n",
    "            ['ITRX MAIN 5Y', ['SX5E'], 'ITRX MAIN 5Y', ['SX5E'], ],\n",
    "            ['ITRX XOVER 5Y', ['SX5E'], 'ITRX XOVER 5Y', ['SX5E'], ],\n",
    "            \n",
    "            ['ITRX MAIN 5Y', ['CDX IG 5Y'], 'ITRX MAIN 5Y', ['CDX IG 5Y'],],\n",
    "            ['ITRX XOVER 5Y', ['CDX HY 5Y'], 'ITRX XOVER 5Y', ['CDX HY 5Y'],],\n",
    "            \n",
    "        ]\n",
    "        l1, t1 = x_model(3, models_list, diff_list, calc)\n",
    "        l2 = pd.concat([l2,l1],axis=1)\n",
    "        times_list += t1  \n",
    "        \n",
    "        models_list = [ \n",
    "            ['EMB', ['EEM'], 'EMB', ['EEM'],],\n",
    "            ['CDX EM 5Y', ['CDX IG 5Y'], 'CDX EM 5Y', ['CDX IG 5Y'],],\n",
    "            ['CDX EM 5Y', ['ITRX XOVER 5Y'], 'CDX EM 5Y', ['ITRX XOVER 5Y'],],\n",
    "            ['CDX EM 5Y', ['EEM'], 'CDX EM 5Y', ['EEM'],],\n",
    "        ]\n",
    "        l1, t1 = x_model(3, models_list, diff_list, calc)\n",
    "        l2 = pd.concat([l2,l1],axis=1)\n",
    "        times_list += t1\n",
    "        all_zscore_values += [[item for item in l2.columns]]\n",
    "    \n",
    "    # ########################################################################################## Combining them\n",
    "    \n",
    "    df = pd.DataFrame({'PX_Zscore 1/2/3w':all_zscore_values[0]})\n",
    "    df['Rtn_Zscore 6/9/12w'] = [item.split(\": \")[1] for item in all_zscore_values[1]]\n",
    "    \n",
    "    df['Pair'] = df['PX_Zscore 1/2/3w'].apply(lambda x: x.split(\" ZScore: \")[0])\n",
    "    df['PX_Zscore 1/2/3w'] = df['PX_Zscore 1/2/3w'].apply(lambda x: x.split(\" ZScore: \")[1])\n",
    "    df['Pair'] = df['Pair'].str.replace(\"(\",\" (\")\n",
    "    df['Long Risk'] = df['Pair'].apply(lambda x: x.split(\" vs. \")[0])\n",
    "    df['Short Risk'] = df['Pair'].apply(lambda x: x.split(\" vs. \")[1])\n",
    "    df = df[['Long Risk','Short Risk','PX_Zscore 1/2/3w','Rtn_Zscore 6/9/12w']]\n",
    "    df['Long Ref.'] = df['Long Risk'].apply(lambda x: x.split(\" (\")[1].replace(\")\",\"\"))\n",
    "    df['Long Risk'] = df['Long Risk'].apply(lambda x: x.split(\" (\")[0].replace(\"CDX \",\"\").\\\n",
    "                                            replace(\"ITRX \",\"\").replace(\" 5Y\",\"\").replace(\"SPX\",\"ESA Implied SPY\"))\n",
    "    df['Short Ref.'] = df['Short Risk'].apply(lambda x: x.split(\" (\")[1].replace(\")\",\"\"))\n",
    "    df['Short Ref.'] = df['Short Ref.'].apply(lambda x: f\"['{x.split(\" & \")[0]}', '{x.split(\" & \")[1]}']\" if \"&\" in x else x)\n",
    "    df['Short Risk'] = df['Short Risk'].apply(lambda x: x.split(\" (\")[0])\n",
    "    df['Short Risk'] = df['Short Risk'].apply(lambda x: x.replace(\"ITRX \",\"\").\\\n",
    "                                              replace(\" 5Y\",\"\").replace(\"SPX\",\"ESA Implied SPY\").replace(\"CDX \",\"\"))\n",
    "    df['Valuation'] = df.apply(lambda row: f\"{row['Long Risk']} {'rich' if eval(row['PX_Zscore 1/2/3w'])\\\n",
    "    >0 else 'cheap'} to {row['Short Risk']}\",axis=1)\n",
    "   \n",
    "    df = df[['Long Risk','Long Ref.','Short Risk','Short Ref.','PX_Zscore 1/2/3w','Rtn_Zscore 6/9/12w','Valuation']].copy()\n",
    "    df['Last Update'] = [item.strftime(\"%d-%b %I:%M %p\") for item in times_list]\n",
    "    df = df.rename(columns={\"Long Ref.\":\"Ref\",\"Short Ref.\":\"Ref.\"})\n",
    "    \n",
    "    formatted_time = bbg_time.strftime(\"%I:%M %p\")\n",
    "    df.columns = pd.MultiIndex.from_tuples([(formatted_time, col) for col in df.columns])\n",
    "    \n",
    "    styled_df = (\n",
    "        df.style\n",
    "        .apply(color_negative_red_positive_green_basis, subset=[df.columns[4]], axis=0)\n",
    "        .apply(color_negative_red_positive_green_basis, subset=[df.columns[5]], axis=0)\n",
    "        .applymap(bold_zscore, subset=pd.IndexSlice[:, df.columns[4]])\n",
    "        .apply(add_black_line, axis=1)\n",
    "        .hide(axis=\"index\")\n",
    "    )\n",
    "    \n",
    "    update_display(styled_df,display_id=\"DFA\")\n",
    "    # bbg_datafile.to_parquet(\"bbg1.parquet\")\n",
    "    # all_intraday_er_series.to_parquet(\"er1.parquet\")\n",
    "    # if datetime.now().time()==pd.to_datetime(\"09:33\").time():\n",
    "    #     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
